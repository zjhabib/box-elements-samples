{"ast":null,"code":"import _regeneratorRuntime from \"/Users/zhabib/Documents/GitHub/box-elements-samples/demo-box-metadata-views/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nfunction _typeof(obj) {\n  \"@babel/helpers - typeof\";\n\n  if (typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\") {\n    _typeof = function _typeof(obj) {\n      return typeof obj;\n    };\n  } else {\n    _typeof = function _typeof(obj) {\n      return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj;\n    };\n  }\n  return _typeof(obj);\n}\nfunction ownKeys(object, enumerableOnly) {\n  var keys = Object.keys(object);\n  if (Object.getOwnPropertySymbols) {\n    var symbols = Object.getOwnPropertySymbols(object);\n    if (enumerableOnly) symbols = symbols.filter(function (sym) {\n      return Object.getOwnPropertyDescriptor(object, sym).enumerable;\n    });\n    keys.push.apply(keys, symbols);\n  }\n  return keys;\n}\nfunction _objectSpread(target) {\n  for (var i = 1; i < arguments.length; i++) {\n    var source = arguments[i] != null ? arguments[i] : {};\n    if (i % 2) {\n      ownKeys(Object(source), true).forEach(function (key) {\n        _defineProperty(target, key, source[key]);\n      });\n    } else if (Object.getOwnPropertyDescriptors) {\n      Object.defineProperties(target, Object.getOwnPropertyDescriptors(source));\n    } else {\n      ownKeys(Object(source)).forEach(function (key) {\n        Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key));\n      });\n    }\n  }\n  return target;\n}\nfunction asyncGeneratorStep(gen, resolve, reject, _next, _throw, key, arg) {\n  try {\n    var info = gen[key](arg);\n    var value = info.value;\n  } catch (error) {\n    reject(error);\n    return;\n  }\n  if (info.done) {\n    resolve(value);\n  } else {\n    Promise.resolve(value).then(_next, _throw);\n  }\n}\nfunction _asyncToGenerator(fn) {\n  return function () {\n    var self = this,\n      args = arguments;\n    return new Promise(function (resolve, reject) {\n      var gen = fn.apply(self, args);\n      function _next(value) {\n        asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"next\", value);\n      }\n      function _throw(err) {\n        asyncGeneratorStep(gen, resolve, reject, _next, _throw, \"throw\", err);\n      }\n      _next(undefined);\n    });\n  };\n}\nfunction _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\nfunction _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  return Constructor;\n}\nfunction _possibleConstructorReturn(self, call) {\n  if (call && (_typeof(call) === \"object\" || typeof call === \"function\")) {\n    return call;\n  }\n  return _assertThisInitialized(self);\n}\nfunction _getPrototypeOf(o) {\n  _getPrototypeOf = Object.setPrototypeOf ? Object.getPrototypeOf : function _getPrototypeOf(o) {\n    return o.__proto__ || Object.getPrototypeOf(o);\n  };\n  return _getPrototypeOf(o);\n}\nfunction _assertThisInitialized(self) {\n  if (self === void 0) {\n    throw new ReferenceError(\"this hasn't been initialised - super() hasn't been called\");\n  }\n  return self;\n}\nfunction _inherits(subClass, superClass) {\n  if (typeof superClass !== \"function\" && superClass !== null) {\n    throw new TypeError(\"Super expression must either be null or a function\");\n  }\n  subClass.prototype = Object.create(superClass && superClass.prototype, {\n    constructor: {\n      value: subClass,\n      writable: true,\n      configurable: true\n    }\n  });\n  if (superClass) _setPrototypeOf(subClass, superClass);\n}\nfunction _setPrototypeOf(o, p) {\n  _setPrototypeOf = Object.setPrototypeOf || function _setPrototypeOf(o, p) {\n    o.__proto__ = p;\n    return o;\n  };\n  return _setPrototypeOf(o, p);\n}\nfunction _defineProperty(obj, key, value) {\n  if (key in obj) {\n    Object.defineProperty(obj, key, {\n      value: value,\n      enumerable: true,\n      configurable: true,\n      writable: true\n    });\n  } else {\n    obj[key] = value;\n  }\n  return obj;\n}\n\n/**\n * \n * @file Multiput upload\n * @author Box\n */\nimport noop from 'lodash/noop';\nimport isNaN from 'lodash/isNaN';\nimport { getFileLastModifiedAsISONoMSIfPossible, getBoundedExpBackoffRetryDelay } from '../../utils/uploads';\nimport { retryNumOfTimes } from '../../utils/function';\nimport { digest } from '../../utils/webcrypto';\nimport hexToBase64 from '../../utils/base64';\nimport createWorker from '../../utils/uploadsSHA1Worker';\nimport { DEFAULT_RETRY_DELAY_MS, ERROR_CODE_UPLOAD_STORAGE_LIMIT_EXCEEDED, HTTP_STATUS_CODE_FORBIDDEN, MS_IN_S } from '../../constants';\nimport MultiputPart, { PART_STATE_UPLOADED, PART_STATE_UPLOADING, PART_STATE_DIGEST_READY, PART_STATE_NOT_STARTED } from './MultiputPart';\nimport BaseMultiput from './BaseMultiput';\n// Constants used for specifying log event types.\n// This type is a catch-all for create session errors that aren't 5xx's (for which we'll do\n// retries) and aren't specific 4xx's we know how to specifically handle (e.g. out of storage).\nvar LOG_EVENT_TYPE_CREATE_SESSION_MISC_ERROR = 'create_session_misc_error';\nvar LOG_EVENT_TYPE_CREATE_SESSION_RETRIES_EXCEEDED = 'create_session_retries_exceeded';\nvar LOG_EVENT_TYPE_FILE_CHANGED_DURING_UPLOAD = 'file_changed_during_upload';\nvar LOG_EVENT_TYPE_PART_UPLOAD_RETRIES_EXCEEDED = 'part_upload_retries_exceeded';\nvar LOG_EVENT_TYPE_COMMIT_RETRIES_EXCEEDED = 'commit_retries_exceeded';\nvar LOG_EVENT_TYPE_WEB_WORKER_ERROR = 'web_worker_error';\nvar LOG_EVENT_TYPE_FILE_READER_RECEIVED_NOT_FOUND_ERROR = 'file_reader_received_not_found_error';\nvar LOG_EVENT_TYPE_PART_DIGEST_RETRIES_EXCEEDED = 'part_digest_retries_exceeded';\nvar MultiputUpload = /*#__PURE__*/\nfunction (_BaseMultiput) {\n  _inherits(MultiputUpload, _BaseMultiput);\n\n  /**\n   * [constructor]\n   *\n   * @param {Options} options\n   * @param {MultiputConfig} [config]\n   */\n  function MultiputUpload(options, config) {\n    var _this;\n    _classCallCheck(this, MultiputUpload);\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(MultiputUpload).call(this, options, {\n      createSession: null,\n      uploadPart: null,\n      listParts: null,\n      commit: null,\n      abort: null,\n      logEvent: null\n    }, config));\n    _defineProperty(_assertThisInitialized(_this), \"getBaseUploadUrlFromPreflightResponse\", function (_ref) {\n      var data = _ref.data;\n      if (!data || !data.upload_url) {\n        return _this.getBaseUploadUrl();\n      }\n      var splitUrl = data.upload_url.split('/'); // splitUrl[0] is the protocol (e.g., https:), splitUrl[2] is hostname (e.g., www.box.com)\n\n      _this.uploadHost = \"\".concat(splitUrl[0], \"//\").concat(splitUrl[2]);\n      return _this.getBaseUploadUrl();\n    });\n    _defineProperty(_assertThisInitialized(_this), \"preflightSuccessHandler\", /*#__PURE__*/\n    function () {\n      var _ref2 = _asyncToGenerator( /*#__PURE__*/\n      _regeneratorRuntime.mark(function _callee(preflightResponse) {\n        var uploadUrl, createSessionUrl, postData, response, errorData;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!_this.isDestroyed()) {\n                  _context.next = 2;\n                  break;\n                }\n                return _context.abrupt(\"return\");\n              case 2:\n                uploadUrl = _this.getBaseUploadUrlFromPreflightResponse(preflightResponse);\n                createSessionUrl = \"\".concat(uploadUrl, \"/files/upload_sessions\"); // Parallelism is currently detrimental to multiput upload performance in Zones, so set it to 1.\n\n                if (createSessionUrl.includes('fupload-ec2')) {\n                  _this.config.parallelism = 1;\n                } // Set up post body\n\n                postData = {\n                  file_size: _this.file.size,\n                  file_name: _this.fileName\n                };\n                if (_this.fileId) {\n                  createSessionUrl = createSessionUrl.replace('upload_sessions', \"\".concat(_this.fileId, \"/upload_sessions\"));\n                } else {\n                  postData.folder_id = _this.folderId;\n                }\n                _context.prev = 7;\n                _context.next = 10;\n                return _this.xhr.post({\n                  url: createSessionUrl,\n                  data: postData\n                });\n              case 10:\n                response = _context.sent;\n                _this.createSessionSuccessHandler(response.data);\n                _context.next = 31;\n                break;\n              case 14:\n                _context.prev = 14;\n                _context.t0 = _context[\"catch\"](7);\n                errorData = _this.getErrorResponse(_context.t0);\n                if (!(errorData && errorData.status >= 500 && errorData.status < 600)) {\n                  _context.next = 20;\n                  break;\n                }\n                _this.createSessionErrorHandler(_context.t0);\n                return _context.abrupt(\"return\");\n              case 20:\n                if (!(errorData && errorData.status === 409 && errorData.code === 'session_conflict')) {\n                  _context.next = 23;\n                  break;\n                }\n                _this.createSessionSuccessHandler(errorData.context_info.session);\n                return _context.abrupt(\"return\");\n              case 23:\n                if (!(errorData && errorData.status === HTTP_STATUS_CODE_FORBIDDEN && errorData.code === ERROR_CODE_UPLOAD_STORAGE_LIMIT_EXCEEDED || errorData.status === HTTP_STATUS_CODE_FORBIDDEN && errorData.code === 'access_denied_insufficient_permissions')) {\n                  _context.next = 26;\n                  break;\n                }\n                _this.errorCallback(errorData);\n                return _context.abrupt(\"return\");\n              case 26:\n                if (!(errorData && errorData.status === 409)) {\n                  _context.next = 30;\n                  break;\n                }\n                _this.resolveConflict(errorData);\n                _this.createSessionRetry();\n                return _context.abrupt(\"return\");\n              case 30:\n                // All other cases get treated as an upload failure.\n                _this.sessionErrorHandler(_context.t0, LOG_EVENT_TYPE_CREATE_SESSION_MISC_ERROR, JSON.stringify(_context.t0));\n              case 31:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, null, [[7, 14]]);\n      }));\n      return function (_x) {\n        return _ref2.apply(this, arguments);\n      };\n    }());\n    _defineProperty(_assertThisInitialized(_this), \"createSessionErrorHandler\", function (error) {\n      if (_this.isDestroyed()) {\n        return;\n      }\n      if (_this.createSessionNumRetriesPerformed < _this.config.retries) {\n        _this.createSessionRetry();\n        return;\n      }\n      _this.consoleLog('Too many create session failures, failing upload');\n      _this.sessionErrorHandler(error, LOG_EVENT_TYPE_CREATE_SESSION_RETRIES_EXCEEDED, JSON.stringify(error));\n    });\n    _defineProperty(_assertThisInitialized(_this), \"getSessionInfo\", /*#__PURE__*/\n    _asyncToGenerator( /*#__PURE__*/\n    _regeneratorRuntime.mark(function _callee2() {\n      var uploadUrl, sessionUrl, response;\n      return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              uploadUrl = _this.getBaseUploadUrl();\n              sessionUrl = \"\".concat(uploadUrl, \"/files/upload_sessions/\").concat(_this.sessionId);\n              _context2.prev = 2;\n              _context2.next = 5;\n              return _this.xhr.get({\n                url: sessionUrl\n              });\n            case 5:\n              response = _context2.sent;\n              _this.getSessionSuccessHandler(response.data);\n              _context2.next = 12;\n              break;\n            case 9:\n              _context2.prev = 9;\n              _context2.t0 = _context2[\"catch\"](2);\n              _this.getSessionErrorHandler(_context2.t0);\n            case 12:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, _callee2, null, [[2, 9]]);\n    })));\n    _defineProperty(_assertThisInitialized(_this), \"partUploadSuccessHandler\", function (part) {\n      _this.numPartsUploading -= 1;\n      _this.numPartsUploaded += 1;\n      _this.updateProgress(part.uploadedBytes, _this.partSize);\n      _this.processNextParts();\n    });\n    _defineProperty(_assertThisInitialized(_this), \"partUploadErrorHandler\", function (error, eventInfo) {\n      _this.sessionErrorHandler(error, LOG_EVENT_TYPE_PART_UPLOAD_RETRIES_EXCEEDED, eventInfo); // Pause the rest of the parts.\n      // can't cancel parts because cancel destroys the part and parts are only created in createSession call\n\n      if (_this.isResumableUploadsEnabled) {\n        // Reset uploading process for parts that were in progress when the upload failed\n        var nextUploadIndex = _this.firstUnuploadedPartIndex;\n        while (_this.numPartsUploading > 0) {\n          var part = _this.parts[nextUploadIndex];\n          if (part && part.state === PART_STATE_UPLOADING) {\n            part.reset();\n            part.pause();\n            _this.numPartsUploading -= 1;\n            _this.numPartsDigestReady += 1;\n          }\n          nextUploadIndex += 1;\n        }\n      }\n    });\n    _defineProperty(_assertThisInitialized(_this), \"updateProgress\", function (prevUploadedBytes, newUploadedBytes) {\n      if (_this.isDestroyed()) {\n        return;\n      }\n      _this.totalUploadedBytes += newUploadedBytes - prevUploadedBytes;\n      _this.progressCallback({\n        loaded: _this.totalUploadedBytes,\n        total: _this.file.size\n      });\n    });\n    _defineProperty(_assertThisInitialized(_this), \"processNextParts\", function () {\n      if (_this.failSessionIfFileChangeDetected()) {\n        return;\n      }\n      if (_this.numPartsUploaded === _this.parts.length && _this.fileSha1) {\n        _this.commitSession();\n        return;\n      }\n      _this.updateFirstUnuploadedPartIndex();\n      while (_this.canStartMorePartUploads()) {\n        _this.uploadNextPart();\n      }\n      if (_this.shouldComputeDigestForNextPart()) {\n        _this.computeDigestForNextPart();\n      }\n    });\n    _defineProperty(_assertThisInitialized(_this), \"onWorkerMessage\", function (event) {\n      if (_this.isDestroyed()) {\n        return;\n      }\n      var data = event.data;\n      if (data.type === 'partDone') {\n        _this.numPartsDigestComputing -= 1;\n        var part = data.part;\n        _this.parts[part.index].timing.fileDigestTime = data.duration;\n        _this.processNextParts();\n      } else if (data.type === 'done') {\n        _this.fileSha1 = hexToBase64(data.sha1);\n        _this.sha1Worker.terminate();\n        _this.processNextParts();\n      } else if (data.type === 'error') {\n        _this.sessionErrorHandler(null, LOG_EVENT_TYPE_WEB_WORKER_ERROR, JSON.stringify(data));\n      }\n    });\n    _defineProperty(_assertThisInitialized(_this), \"sendPartToWorker\", function (part, buffer) {\n      if (_this.isDestroyed()) {\n        return;\n      } // Don't send entire part since XHR can't be cloned\n\n      var partInformation = {\n        index: part.index,\n        offset: part.offset,\n        size: part.partSize\n      };\n      _this.sha1Worker.postMessage({\n        part: partInformation,\n        fileSize: _this.file.size,\n        partContents: buffer\n      }, [buffer] // This transfers the ArrayBuffer to the worker context without copying contents.\n      );\n\n      _this.consoleLog(\"Part sent to worker: \".concat(JSON.stringify(part), \".}\"));\n    });\n    _defineProperty(_assertThisInitialized(_this), \"onPartDigestError\", function (error, part) {\n      _this.consoleLog(\"Error computing digest for part \".concat(JSON.stringify(part), \": \").concat(JSON.stringify(error))); // When a FileReader is processing a file that changes on disk, Chrome reports a 'NotFoundError'\n      // and Safari reports a 'NOT_FOUND_ERR'. (Other browsers seem to allow the reader to keep\n      // going, either with the old version of the new file or the new one.) Since the error name\n      // implies that retrying will not help, we fail the session.\n\n      if (error.name === 'NotFoundError' || error.name === 'NOT_FOUND_ERR') {\n        _this.sessionErrorHandler(null, LOG_EVENT_TYPE_FILE_READER_RECEIVED_NOT_FOUND_ERROR, JSON.stringify(error));\n        return;\n      }\n      if (_this.failSessionIfFileChangeDetected()) {\n        return;\n      }\n      if (part.numDigestRetriesPerformed >= _this.config.retries) {\n        _this.sessionErrorHandler(null, LOG_EVENT_TYPE_PART_DIGEST_RETRIES_EXCEEDED, JSON.stringify(error));\n        return;\n      }\n      var retryDelayMs = getBoundedExpBackoffRetryDelay(_this.config.initialRetryDelayMs, _this.config.maxRetryDelayMs, part.numDigestRetriesPerformed);\n      part.numDigestRetriesPerformed += 1;\n      _this.consoleLog(\"Retrying digest work for part \".concat(JSON.stringify(part), \" in \").concat(retryDelayMs, \" ms\"));\n      setTimeout(function () {\n        _this.computeDigestForPart(part);\n      }, retryDelayMs);\n    });\n    _defineProperty(_assertThisInitialized(_this), \"commitSession\", function () {\n      if (_this.isDestroyed()) {\n        return;\n      }\n      var stats = {\n        totalPartReadTime: 0,\n        totalPartDigestTime: 0,\n        totalFileDigestTime: 0,\n        totalPartUploadTime: 0\n      };\n      var data = {\n        parts: _this.parts.map(function (part) {\n          stats.totalPartReadTime += part.timing.readTime;\n          stats.totalPartDigestTime += part.timing.subtleCryptoTime;\n          stats.totalFileDigestTime += part.timing.fileDigestTime;\n          stats.totalPartUploadTime += part.timing.uploadTime;\n          return part.getPart();\n        }).sort(function (part1, part2) {\n          return part1.offset - part2.offset;\n        }),\n        attributes: {}\n      };\n      var fileLastModified = getFileLastModifiedAsISONoMSIfPossible(_this.file);\n      if (fileLastModified) {\n        data.attributes.content_modified_at = fileLastModified;\n      }\n      if (_this.fileDescription) {\n        data.attributes.description = _this.fileDescription;\n      }\n      var clientEventInfo = {\n        avg_part_read_time: Math.round(stats.totalPartReadTime / _this.parts.length),\n        avg_part_digest_time: Math.round(stats.totalPartDigestTime / _this.parts.length),\n        avg_file_digest_time: Math.round(stats.totalFileDigestTime / _this.parts.length),\n        avg_part_upload_time: Math.round(stats.totalPartUploadTime / _this.parts.length)\n      }; // To make flow stop complaining about this.fileSha1 could potentially be undefined/null\n\n      var fileSha1 = _this.fileSha1;\n      var headers = {\n        Digest: \"sha=\".concat(fileSha1),\n        'X-Box-Client-Event-Info': JSON.stringify(clientEventInfo)\n      };\n      _this.xhr.post({\n        url: _this.sessionEndpoints.commit,\n        data: data,\n        headers: headers\n      }).then(_this.commitSessionSuccessHandler).catch(_this.commitSessionErrorHandler);\n    });\n    _defineProperty(_assertThisInitialized(_this), \"commitSessionSuccessHandler\", function (response) {\n      if (_this.isDestroyed()) {\n        return;\n      }\n      var status = response.status,\n        data = response.data;\n      if (status === 202) {\n        _this.commitSessionRetry(response);\n        return;\n      }\n      var entries = data.entries; // v2.1 API response format is different from v2.0. v2.1 returns individual upload entry directly inside data,\n      // while v2.0 returns a collection of entries under data.entries\n\n      if (!entries && data.id) {\n        entries = [data];\n      }\n      _this.destroy();\n      if (_this.successCallback && entries) {\n        _this.successCallback(entries);\n      }\n    });\n    _defineProperty(_assertThisInitialized(_this), \"commitSessionErrorHandler\", function (error) {\n      if (_this.isDestroyed()) {\n        return;\n      }\n      var response = error.response;\n      if (!response) {\n        // Some random error happened\n        _this.consoleError(error);\n        return;\n      }\n      if (_this.commitRetryCount >= _this.config.retries) {\n        _this.consoleLog('Too many commit failures, failing upload');\n        _this.sessionErrorHandler(error, LOG_EVENT_TYPE_COMMIT_RETRIES_EXCEEDED, JSON.stringify(error));\n        return;\n      }\n      _this.commitSessionRetry(response);\n    });\n    _defineProperty(_assertThisInitialized(_this), \"getNumPartsUploading\", function () {\n      return _this.numPartsUploading;\n    });\n    _this.parts = [];\n    _this.options = options;\n    _this.fileSha1 = null;\n    _this.totalUploadedBytes = 0;\n    _this.numPartsNotStarted = 0; // # of parts yet to be processed\n\n    _this.numPartsDigestComputing = 0; // # of parts sent to the digest worker\n\n    _this.numPartsDigestReady = 0; // # of parts with digest finished that are waiting to be uploaded.\n\n    _this.numPartsUploading = 0; // # of parts with upload requests currently inflight\n\n    _this.numPartsUploaded = 0; // # of parts successfully uploaded\n\n    _this.firstUnuploadedPartIndex = 0; // Index of first part that hasn't been uploaded yet.\n\n    _this.createSessionNumRetriesPerformed = 0;\n    _this.partSize = 0;\n    _this.commitRetryCount = 0;\n    _this.clientId = null;\n    _this.isResumableUploadsEnabled = false;\n    _this.numResumeRetries = 0;\n    return _this;\n  }\n  /**\n   * Reset values for uploading process.\n   */\n\n  _createClass(MultiputUpload, [{\n    key: \"reset\",\n    value: function reset() {\n      this.parts = [];\n      this.fileSha1 = null;\n      this.totalUploadedBytes = 0;\n      this.numPartsNotStarted = 0; // # of parts yet to be processed\n\n      this.numPartsDigestComputing = 0; // # of parts sent to the digest worker\n\n      this.numPartsDigestReady = 0; // # of parts with digest finished that are waiting to be uploaded.\n\n      this.numPartsUploading = 0; // # of parts with upload requests currently inflight\n\n      this.numPartsUploaded = 0; // # of parts successfully uploaded\n\n      this.firstUnuploadedPartIndex = 0; // Index of first part that hasn't been uploaded yet.\n\n      this.createSessionNumRetriesPerformed = 0;\n      this.partSize = 0;\n      this.commitRetryCount = 0;\n      this.numResumeRetries = 0;\n    }\n    /**\n     * Set information about file being uploaded\n     *\n     *\n     * @param {Object} options\n     * @param {File} options.file\n     * @param {string} options.folderId - Untyped folder id (e.g. no \"folder_\" prefix)\n     * @param {string} [options.fileId] - Untyped file id (e.g. no \"file_\" prefix)\n     * @param {string} options.sessionId\n     * @param {Function} [options.errorCallback]\n     * @param {Function} [options.progressCallback]\n     * @param {Function} [options.successCallback]\n     * @return {void}\n     */\n  }, {\n    key: \"setFileInfo\",\n    value: function setFileInfo(_ref4) {\n      var file = _ref4.file,\n        folderId = _ref4.folderId,\n        errorCallback = _ref4.errorCallback,\n        progressCallback = _ref4.progressCallback,\n        successCallback = _ref4.successCallback,\n        _ref4$overwrite = _ref4.overwrite,\n        overwrite = _ref4$overwrite === void 0 ? true : _ref4$overwrite,\n        conflictCallback = _ref4.conflictCallback,\n        fileId = _ref4.fileId;\n      this.file = file;\n      this.fileName = this.file.name;\n      this.folderId = folderId;\n      this.errorCallback = errorCallback || noop;\n      this.progressCallback = progressCallback || noop;\n      this.successCallback = successCallback || noop;\n      this.overwrite = overwrite;\n      this.conflictCallback = conflictCallback;\n      this.fileId = fileId;\n    }\n    /**\n     * Upload a given file\n     *\n     *\n     * @param {Object} options\n     * @param {File} options.file\n     * @param {string} options.folderId - Untyped folder id (e.g. no \"folder_\" prefix)\n     * @param {string} [options.fileId] - Untyped file id (e.g. no \"file_\" prefix)\n     * @param {Function} [options.errorCallback]\n     * @param {Function} [options.progressCallback]\n     * @param {Function} [options.successCallback]\n     * @return {void}\n     */\n  }, {\n    key: \"upload\",\n    value: function upload(_ref5) {\n      var file = _ref5.file,\n        fileDescription = _ref5.fileDescription,\n        folderId = _ref5.folderId,\n        errorCallback = _ref5.errorCallback,\n        progressCallback = _ref5.progressCallback,\n        successCallback = _ref5.successCallback,\n        _ref5$overwrite = _ref5.overwrite,\n        overwrite = _ref5$overwrite === void 0 ? true : _ref5$overwrite,\n        conflictCallback = _ref5.conflictCallback,\n        fileId = _ref5.fileId;\n      this.file = file;\n      this.fileName = this.file.name; // These values are used as part of our (best effort) attempt to abort uploads if we detect\n      // a file change during the upload.\n\n      this.initialFileSize = this.file.size;\n      this.initialFileLastModified = getFileLastModifiedAsISONoMSIfPossible(this.file);\n      this.folderId = folderId;\n      this.errorCallback = errorCallback || noop;\n      this.progressCallback = progressCallback || noop;\n      this.successCallback = successCallback || noop;\n      this.sha1Worker = createWorker();\n      this.sha1Worker.addEventListener('message', this.onWorkerMessage);\n      this.conflictCallback = conflictCallback;\n      this.overwrite = overwrite;\n      this.fileId = fileId;\n      this.fileDescription = fileDescription;\n      this.makePreflightRequest();\n    }\n    /**\n     * Update uploadHost with preflight response and return the base uploadUrl\n     *\n     * @private\n     * @param {Object} response\n     * @param {Object} [response.data]\n     * @return {string}\n     */\n  }, {\n    key: \"createSessionRetry\",\n    /**\n     * Schedule a retry for create session request upon failure\n     *\n     * @private\n     * @return {void}\n     */\n    value: function createSessionRetry() {\n      var retryDelayMs = getBoundedExpBackoffRetryDelay(this.config.initialRetryDelayMs, this.config.maxRetryDelayMs, this.createSessionNumRetriesPerformed);\n      this.createSessionNumRetriesPerformed += 1;\n      this.consoleLog(\"Retrying create session in \".concat(retryDelayMs, \" ms\"));\n      this.createSessionTimeout = setTimeout(this.makePreflightRequest, retryDelayMs);\n    }\n    /**\n     * Handles a upload session success response\n     *\n     * @private\n     * @param {Object} data - Upload session creation success data\n     * @return {void}\n     */\n  }, {\n    key: \"createSessionSuccessHandler\",\n    value: function createSessionSuccessHandler(data) {\n      if (this.isDestroyed()) {\n        return;\n      }\n      var id = data.id,\n        part_size = data.part_size,\n        session_endpoints = data.session_endpoints;\n      this.sessionId = id;\n      this.partSize = part_size;\n      this.sessionEndpoints = _objectSpread({}, this.sessionEndpoints, {\n        uploadPart: session_endpoints.upload_part,\n        listParts: session_endpoints.list_parts,\n        commit: session_endpoints.commit,\n        abort: session_endpoints.abort,\n        logEvent: session_endpoints.log_event\n      });\n      this.populateParts();\n      this.processNextParts();\n    }\n    /**\n     * Resume uploading the given file\n     *\n     *\n     * @param {Object} options\n     * @param {File} options.file\n     * @param {string} options.folderId - Untyped folder id (e.g. no \"folder_\" prefix)\n     * @param {string} [options.fileId] - Untyped file id (e.g. no \"file_\" prefix)\n     * @param {string} options.sessionId\n     * @param {Function} [options.errorCallback]\n     * @param {Function} [options.progressCallback]\n     * @param {Function} [options.successCallback]\n     * @param {Function} [options.conflictCallback]\n     * @return {void}\n     */\n  }, {\n    key: \"resume\",\n    value: function resume(_ref6) {\n      var file = _ref6.file,\n        folderId = _ref6.folderId,\n        errorCallback = _ref6.errorCallback,\n        progressCallback = _ref6.progressCallback,\n        sessionId = _ref6.sessionId,\n        successCallback = _ref6.successCallback,\n        _ref6$overwrite = _ref6.overwrite,\n        overwrite = _ref6$overwrite === void 0 ? true : _ref6$overwrite,\n        conflictCallback = _ref6.conflictCallback,\n        fileId = _ref6.fileId;\n      this.setFileInfo({\n        file: file,\n        folderId: folderId,\n        errorCallback: errorCallback,\n        progressCallback: progressCallback,\n        successCallback: successCallback,\n        conflictCallback: conflictCallback,\n        overwrite: overwrite,\n        fileId: fileId\n      });\n      this.sessionId = sessionId;\n      if (!this.sha1Worker) {\n        this.sha1Worker = createWorker();\n      }\n      this.sha1Worker.addEventListener('message', this.onWorkerMessage);\n      this.getSessionInfo();\n    }\n    /**\n     * Get session information from API.\n     * Uses session info to commit a complete session or continue an in-progress session.\n     *\n     * @private\n     * @return {void}\n     */\n  }, {\n    key: \"getSessionSuccessHandler\",\n    /**\n     * Handles a getSessionInfo success and either commits the session or continues to process\n     * the parts that still need to be uploaded.\n     *\n     * @param response\n     * @return {void}\n     */\n    value: function getSessionSuccessHandler(data) {\n      var part_size = data.part_size,\n        session_endpoints = data.session_endpoints; // Set session information gotten from API response\n\n      this.partSize = part_size;\n      this.sessionEndpoints = _objectSpread({}, this.sessionEndpoints, {\n        uploadPart: session_endpoints.upload_part,\n        listParts: session_endpoints.list_parts,\n        commit: session_endpoints.commit,\n        abort: session_endpoints.abort,\n        logEvent: session_endpoints.log_event\n      });\n      this.processNextParts();\n    }\n    /**\n     * Handle error from getting upload session.\n     * Restart uploads without valid sessions from the beginning of the upload process.\n     *\n     * @param error\n     * @return {void}\n     */\n  }, {\n    key: \"getSessionErrorHandler\",\n    value: function getSessionErrorHandler(error) {\n      if (this.isDestroyed()) {\n        return;\n      }\n      var errorData = this.getErrorResponse(error);\n      if (this.numResumeRetries > this.config.retries) {\n        this.errorCallback(errorData);\n        return;\n      }\n      if (errorData && errorData.status === 429) {\n        var retryAfterMs = DEFAULT_RETRY_DELAY_MS;\n        if (errorData.headers) {\n          var retryAfterSec = parseInt(errorData.headers['retry-after'] || errorData.headers.get('Retry-After'), 10);\n          if (!isNaN(retryAfterSec)) {\n            retryAfterMs = retryAfterSec * MS_IN_S;\n          }\n        }\n        this.retryTimeout = setTimeout(this.getSessionInfo, retryAfterMs);\n        this.numResumeRetries += 1;\n      } else if (errorData && errorData.status >= 400 && errorData.status < 500) {\n        // Restart upload process for errors resulting from invalid/expired session or no permission\n        this.parts.forEach(function (part) {\n          part.cancel();\n        });\n        this.reset(); // Abort session\n\n        clearTimeout(this.createSessionTimeout);\n        clearTimeout(this.commitSessionTimeout);\n        this.abortSession(); // Restart the uploading process from the beginning\n\n        var uploadOptions = {\n          file: this.file,\n          folderId: this.folderId,\n          errorCallback: this.errorCallback,\n          progressCallback: this.progressCallback,\n          successCallback: this.successCallback,\n          overwrite: this.overwrite,\n          fileId: this.fileId\n        };\n        this.upload(uploadOptions);\n      } else {\n        // Handle internet disconnects (error.request && !error.response) and (!error.request)\n        // Also handle any 500 error messages\n        this.retryTimeout = setTimeout(this.getSessionInfo, Math.pow(2, this.numResumeRetries) * MS_IN_S);\n        this.numResumeRetries += 1;\n      }\n    }\n    /**\n     * Session error handler.\n     * Retries the create session request or fails the upload.\n     *\n     * @private\n     * @param {?Error} error\n     * @param {string} logEventType\n     * @param {string} [logMessage]\n     * @return {Promise}\n     */\n  }, {\n    key: \"sessionErrorHandler\",\n    value: function () {\n      var _sessionErrorHandler = _asyncToGenerator( /*#__PURE__*/\n      _regeneratorRuntime.mark(function _callee3(error, logEventType, logMessage) {\n        var _this2 = this;\n        var errorData;\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                if (!this.isResumableUploadsEnabled) {\n                  this.destroy();\n                }\n                errorData = this.getErrorResponse(error);\n                this.errorCallback(errorData);\n                _context3.prev = 3;\n                if (this.sessionEndpoints.logEvent) {\n                  _context3.next = 6;\n                  break;\n                }\n                throw new Error('logEvent endpoint not found');\n              case 6:\n                _context3.next = 8;\n                return retryNumOfTimes(function (resolve, reject) {\n                  _this2.logEvent(logEventType, logMessage).then(resolve).catch(reject);\n                }, this.config.retries, this.config.initialRetryDelayMs);\n              case 8:\n                if (!this.isResumableUploadsEnabled) {\n                  this.abortSession();\n                }\n                _context3.next = 14;\n                break;\n              case 11:\n                _context3.prev = 11;\n                _context3.t0 = _context3[\"catch\"](3);\n                if (!this.isResumableUploadsEnabled) {\n                  this.abortSession();\n                }\n              case 14:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this, [[3, 11]]);\n      }));\n      function sessionErrorHandler(_x2, _x3, _x4) {\n        return _sessionErrorHandler.apply(this, arguments);\n      }\n      return sessionErrorHandler;\n    }()\n    /**\n     * Aborts the upload session\n     *\n     * @private\n     * @return {void}\n     */\n  }, {\n    key: \"abortSession\",\n    value: function abortSession() {\n      var _this3 = this;\n      if (this.sha1Worker) {\n        this.sha1Worker.terminate();\n      }\n      if (this.sessionEndpoints.abort && this.sessionId) {\n        this.xhr.delete({\n          url: this.sessionEndpoints.abort\n        }).then(function () {\n          _this3.sessionId = '';\n        });\n      }\n    }\n    /**\n     * Part upload success handler\n     *\n     * @private\n     * @param {MultiputPart} part\n     * @return {void}\n     */\n  }, {\n    key: \"shouldComputeDigestForNextPart\",\n    /**\n     * We compute digest for parts one at a time.  This is done for simplicity and also to guarantee that\n     * we send parts in order to the web sha1Worker (which is computing the digest for the entire file).\n     *\n     * @private\n     * @return {boolean} true if there is work to do, false otherwise.\n     */\n    value: function shouldComputeDigestForNextPart() {\n      return !this.isDestroyed() && this.numPartsDigestComputing === 0 && this.numPartsNotStarted > 0 && this.numPartsDigestReady < this.config.digestReadahead;\n    }\n    /**\n     * Find first part in parts array that doesn't have a digest, and compute its digest.\n      * @private\n     * @return {void}\n     */\n  }, {\n    key: \"computeDigestForNextPart\",\n    value: function computeDigestForNextPart() {\n      for (var i = this.firstUnuploadedPartIndex; i < this.parts.length; i += 1) {\n        var part = this.parts[i];\n        if (part.state === PART_STATE_NOT_STARTED) {\n          // Update the counters here instead of computeDigestForPart because computeDigestForPart\n          // can get called on retries\n          this.numPartsNotStarted -= 1;\n          this.numPartsDigestComputing += 1;\n          this.computeDigestForPart(part);\n          return;\n        }\n      }\n    }\n    /**\n     * Compute digest for this part\n     *\n     * @private\n     * @param {MultiputPart} part\n     * @return {Promise}\n     */\n  }, {\n    key: \"computeDigestForPart\",\n    value: function () {\n      var _computeDigestForPart = _asyncToGenerator( /*#__PURE__*/\n      _regeneratorRuntime.mark(function _callee4(part) {\n        var blob, reader, startTimestamp, _ref7, buffer, readCompleteTimestamp, sha256ArrayBuffer, sha256, digestCompleteTimestamp;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                blob = this.file.slice(part.offset, part.offset + this.partSize);\n                reader = new window.FileReader();\n                startTimestamp = Date.now();\n                _context4.prev = 3;\n                _context4.next = 6;\n                return this.readFile(reader, blob);\n              case 6:\n                _ref7 = _context4.sent;\n                buffer = _ref7.buffer;\n                readCompleteTimestamp = _ref7.readCompleteTimestamp;\n                _context4.next = 11;\n                return digest('SHA-256', buffer);\n              case 11:\n                sha256ArrayBuffer = _context4.sent;\n                sha256 = btoa([].reduce.call(new Uint8Array(sha256ArrayBuffer), function (data, byte) {\n                  return data + String.fromCharCode(byte);\n                }, ''));\n                this.sendPartToWorker(part, buffer);\n                part.sha256 = sha256;\n                part.state = PART_STATE_DIGEST_READY;\n                part.blob = blob;\n                this.numPartsDigestReady += 1;\n                digestCompleteTimestamp = Date.now();\n                part.timing = {\n                  partDigestTime: digestCompleteTimestamp - startTimestamp,\n                  readTime: readCompleteTimestamp - startTimestamp,\n                  subtleCryptoTime: digestCompleteTimestamp - readCompleteTimestamp\n                };\n                this.processNextParts();\n                _context4.next = 26;\n                break;\n              case 23:\n                _context4.prev = 23;\n                _context4.t0 = _context4[\"catch\"](3);\n                this.onPartDigestError(_context4.t0, part);\n              case 26:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this, [[3, 23]]);\n      }));\n      function computeDigestForPart(_x5) {\n        return _computeDigestForPart.apply(this, arguments);\n      }\n      return computeDigestForPart;\n    }()\n    /**\n     * Deal with a message from the worker (either a part sha-1 ready, file sha-1 ready, or error).\n     *\n     * @private\n     * @param {object} event\n     * @return {void}\n     */\n  }, {\n    key: \"commitSessionRetry\",\n    /**\n     * Retry commit.\n     * Retries the commit or fails the multiput session.\n     *\n     * @private\n     * @param {Object} response\n     * @return {void}\n     */\n    value: function commitSessionRetry(response) {\n      var status = response.status,\n        headers = response.headers;\n      var retryAfterMs = DEFAULT_RETRY_DELAY_MS;\n      if (headers) {\n        var retryAfterSec = parseInt(headers['retry-after'], 10);\n        if (!Number.isNaN(retryAfterSec)) {\n          retryAfterMs = retryAfterSec * 1000;\n        }\n      }\n      var defaultRetryDelayMs = getBoundedExpBackoffRetryDelay(this.config.initialRetryDelayMs, this.config.maxRetryDelayMs, this.commitRetryCount); // If status is 202 then don't increment the retry count.\n      // In this case, frontend will keep retrying until it gets another status code.\n      // Retry interval = value specified for the Retry-After header in 202 response.\n\n      if (status !== 202) {\n        this.commitRetryCount += 1;\n      }\n      var retryDelayMs = retryAfterMs || defaultRetryDelayMs;\n      this.consoleLog(\"Retrying commit in \".concat(retryDelayMs, \" ms\"));\n      this.commitSessionTimeout = setTimeout(this.commitSession, retryDelayMs);\n    }\n    /**\n     * Find first part in parts array that we can upload, and upload it.\n     *\n     * @private\n     * @return {void}\n     */\n  }, {\n    key: \"uploadNextPart\",\n    value: function uploadNextPart() {\n      for (var i = this.firstUnuploadedPartIndex; i < this.parts.length; i += 1) {\n        var part = this.parts[i];\n        if (part.state === PART_STATE_DIGEST_READY) {\n          // Update the counters here instead of uploadPart because uploadPart\n          // can get called on retries\n          this.numPartsDigestReady -= 1;\n          this.numPartsUploading += 1;\n          if (part.isPaused) {\n            part.unpause();\n          } else {\n            part.upload();\n          }\n          break;\n        }\n      }\n    }\n    /**\n     * Checks if upload pipeline is full\n     *\n     * @private\n     * @return {boolean}\n     */\n  }, {\n    key: \"canStartMorePartUploads\",\n    value: function canStartMorePartUploads() {\n      return !this.isDestroyed() && this.numPartsUploading < this.config.parallelism && this.numPartsDigestReady > 0;\n    }\n    /**\n     * Functions that walk the parts array get called a lot, so we cache which part we should\n     * start work at to avoid always iterating through entire parts list.\n     *\n     * @private\n     * @return {void}\n     */\n  }, {\n    key: \"updateFirstUnuploadedPartIndex\",\n    value: function updateFirstUnuploadedPartIndex() {\n      var part = this.parts[this.firstUnuploadedPartIndex];\n      while (part && part.state === PART_STATE_UPLOADED) {\n        this.firstUnuploadedPartIndex += 1;\n        part = this.parts[this.firstUnuploadedPartIndex];\n      }\n    }\n    /**\n     * Get number of parts being uploaded\n     *\n     * @return {number}\n     */\n  }, {\n    key: \"populateParts\",\n    /**\n     * After session is created and we know the part size, populate the parts\n     * array.\n     *\n     * @private\n     * @return {void}\n     */\n    value: function populateParts() {\n      this.numPartsNotStarted = Math.ceil(this.file.size / this.partSize);\n      for (var i = 0; i < this.numPartsNotStarted; i += 1) {\n        var offset = i * this.partSize;\n        var currentPartSize = Math.min(offset + this.partSize, this.file.size) - offset;\n        var part = new MultiputPart(this.options, i, offset, currentPartSize, this.file.size, this.sessionId, this.sessionEndpoints, this.config, this.getNumPartsUploading, this.partUploadSuccessHandler, this.updateProgress, this.partUploadErrorHandler);\n        this.parts.push(part);\n      }\n    }\n    /**\n     * Fails the session if the file's size or last modified has changed since the upload process\n     * began.\n     *\n     * This ensures that we don't upload a file that has parts from one file version and parts from\n     * another file version.\n     *\n     * This logic + the \"not found\" error logic in onWorkerError() is best effort and will not\n     * detect all possible file changes. This is because of browser differences. For example,\n     * -- In Safari, size and last modified will update when a file changes, and workers will\n     * get \"not found\" errors.\n     * -- In Chrome, size and last modified will update, but not in legacy drag and drop (that\n     * code path constructs a different file object). Workers will still get \"not found\" errors,\n     * though, so we can still detect changes even in legacy drag and drop.\n     * -- In IE 11/Edge, size will update but last modified will not. Workers will not get\n     * \"not found\" errors, but they may get a generic error saying that some bytes failed to be\n     * read.\n     * -- In Firefox, neither last modified nor size will update. Workers don't seem to get errors.\n     * (Not a whole lot we can do here...)\n     *\n     * Unfortunately, alternative solutions to catch more cases don't have a clear ROI (for\n     * example, doing a SHA-1 of the file before and after the upload is very expensive), so\n     * this is the best solution we have. We can revisit this if data shows that we need a better\n     * solution.\n     *\n     * @private\n     * @return {boolean} True if the session was failed, false if no action was taken\n     */\n  }, {\n    key: \"failSessionIfFileChangeDetected\",\n    value: function failSessionIfFileChangeDetected() {\n      var currentFileSize = this.file.size;\n      var currentFileLastModified = getFileLastModifiedAsISONoMSIfPossible(this.file);\n      if (currentFileSize !== this.initialFileSize || currentFileLastModified !== this.initialFileLastModified) {\n        this.sessionErrorHandler(null, LOG_EVENT_TYPE_FILE_CHANGED_DURING_UPLOAD, JSON.stringify({\n          oldSize: this.initialFileSize,\n          newSize: currentFileSize,\n          oldLastModified: this.initialFileLastModified,\n          newLastModified: currentFileLastModified\n        }));\n        return true;\n      }\n      return false;\n    }\n    /**\n     * Cancels an upload in progress by cancelling all upload parts.\n     * This cannot be undone or resumed.\n     *\n     * @private\n     * @return {void}\n     */\n  }, {\n    key: \"cancel\",\n    value: function cancel() {\n      if (this.isDestroyed()) {\n        return;\n      } // Cancel individual upload parts\n\n      this.parts.forEach(function (part) {\n        part.cancel();\n      });\n      this.parts = [];\n      clearTimeout(this.createSessionTimeout);\n      clearTimeout(this.commitSessionTimeout);\n      this.abortSession();\n      this.destroy();\n    }\n    /**\n     * Resolves upload conflict by overwriting or renaming\n     *\n     * @param {Object} response data\n     * @return {Promise}\n     */\n  }, {\n    key: \"resolveConflict\",\n    value: function () {\n      var _resolveConflict = _asyncToGenerator( /*#__PURE__*/\n      _regeneratorRuntime.mark(function _callee5(data) {\n        var extension;\n        return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n          while (1) {\n            switch (_context5.prev = _context5.next) {\n              case 0:\n                if (!(this.overwrite && data.context_info)) {\n                  _context5.next = 3;\n                  break;\n                }\n                this.fileId = data.context_info.conflicts.id;\n                return _context5.abrupt(\"return\");\n              case 3:\n                if (!this.conflictCallback) {\n                  _context5.next = 6;\n                  break;\n                }\n                this.fileName = this.conflictCallback(this.fileName);\n                return _context5.abrupt(\"return\");\n              case 6:\n                extension = this.fileName.substr(this.fileName.lastIndexOf('.')) || ''; // foo.txt => foo-1513385827917.txt\n\n                this.fileName = \"\".concat(this.fileName.substr(0, this.fileName.lastIndexOf('.')), \"-\").concat(Date.now()).concat(extension);\n              case 8:\n              case \"end\":\n                return _context5.stop();\n            }\n          }\n        }, _callee5, this);\n      }));\n      function resolveConflict(_x6) {\n        return _resolveConflict.apply(this, arguments);\n      }\n      return resolveConflict;\n    }()\n    /**\n     * Returns detailed error response\n     *\n     * @param {Object} error\n     * @return {Object}\n     */\n  }, {\n    key: \"getErrorResponse\",\n    value: function getErrorResponse(error) {\n      if (!error) {\n        return {};\n      }\n      var response = error.response;\n      if (!response) {\n        return {};\n      }\n      if (response.status === 401) {\n        return response;\n      }\n      return response.data;\n    }\n  }]);\n  return MultiputUpload;\n}(BaseMultiput);\nexport default MultiputUpload;","map":{"version":3,"sources":["../../../src/api/uploads/MultiputUpload.js"],"names":["noop","isNaN","getFileLastModifiedAsISONoMSIfPossible","getBoundedExpBackoffRetryDelay","retryNumOfTimes","digest","hexToBase64","createWorker","DEFAULT_RETRY_DELAY_MS","ERROR_CODE_UPLOAD_STORAGE_LIMIT_EXCEEDED","HTTP_STATUS_CODE_FORBIDDEN","MS_IN_S","MultiputPart","PART_STATE_UPLOADED","PART_STATE_UPLOADING","PART_STATE_DIGEST_READY","PART_STATE_NOT_STARTED","BaseMultiput","LOG_EVENT_TYPE_CREATE_SESSION_MISC_ERROR","LOG_EVENT_TYPE_CREATE_SESSION_RETRIES_EXCEEDED","LOG_EVENT_TYPE_FILE_CHANGED_DURING_UPLOAD","LOG_EVENT_TYPE_PART_UPLOAD_RETRIES_EXCEEDED","LOG_EVENT_TYPE_COMMIT_RETRIES_EXCEEDED","LOG_EVENT_TYPE_WEB_WORKER_ERROR","LOG_EVENT_TYPE_FILE_READER_RECEIVED_NOT_FOUND_ERROR","LOG_EVENT_TYPE_PART_DIGEST_RETRIES_EXCEEDED","MultiputUpload","options","config","createSession","uploadPart","listParts","commit","abort","logEvent","parts","fileSha1","totalUploadedBytes","numPartsNotStarted","numPartsDigestComputing","numPartsDigestReady","numPartsUploading","numPartsUploaded","firstUnuploadedPartIndex","createSessionNumRetriesPerformed","partSize","commitRetryCount","clientId","isResumableUploadsEnabled","numResumeRetries","file","folderId","errorCallback","progressCallback","successCallback","overwrite","conflictCallback","fileId","fileName","name","fileDescription","initialFileSize","size","initialFileLastModified","sha1Worker","addEventListener","onWorkerMessage","makePreflightRequest","data","upload_url","getBaseUploadUrl","splitUrl","split","uploadHost","preflightResponse","isDestroyed","uploadUrl","getBaseUploadUrlFromPreflightResponse","createSessionUrl","includes","parallelism","postData","file_size","file_name","replace","folder_id","response","xhr","post","url","createSessionSuccessHandler","errorData","getErrorResponse","status","createSessionErrorHandler","code","context_info","session","resolveConflict","createSessionRetry","sessionErrorHandler","JSON","stringify","error","retries","consoleLog","retryDelayMs","initialRetryDelayMs","maxRetryDelayMs","createSessionTimeout","setTimeout","id","part_size","session_endpoints","sessionId","sessionEndpoints","upload_part","list_parts","log_event","populateParts","processNextParts","setFileInfo","getSessionInfo","sessionUrl","get","getSessionSuccessHandler","getSessionErrorHandler","retryAfterMs","headers","retryAfterSec","parseInt","retryTimeout","forEach","part","cancel","reset","clearTimeout","commitSessionTimeout","abortSession","uploadOptions","upload","logEventType","logMessage","destroy","Error","resolve","reject","then","catch","terminate","delete","updateProgress","uploadedBytes","eventInfo","nextUploadIndex","state","pause","prevUploadedBytes","newUploadedBytes","loaded","total","failSessionIfFileChangeDetected","length","commitSession","updateFirstUnuploadedPartIndex","canStartMorePartUploads","uploadNextPart","shouldComputeDigestForNextPart","computeDigestForNextPart","digestReadahead","i","computeDigestForPart","blob","slice","offset","reader","window","FileReader","startTimestamp","Date","now","buffer","readCompleteTimestamp","readFile","sha256ArrayBuffer","sha256","btoa","reduce","call","Uint8Array","byte","String","fromCharCode","sendPartToWorker","digestCompleteTimestamp","timing","partDigestTime","readTime","subtleCryptoTime","onPartDigestError","event","type","index","fileDigestTime","duration","sha1","partInformation","postMessage","fileSize","partContents","numDigestRetriesPerformed","stats","totalPartReadTime","totalPartDigestTime","totalFileDigestTime","totalPartUploadTime","map","uploadTime","getPart","sort","part1","part2","attributes","fileLastModified","content_modified_at","description","clientEventInfo","avg_part_read_time","Math","round","avg_part_digest_time","avg_file_digest_time","avg_part_upload_time","Digest","commitSessionSuccessHandler","commitSessionErrorHandler","commitSessionRetry","entries","consoleError","Number","defaultRetryDelayMs","isPaused","unpause","ceil","currentPartSize","min","getNumPartsUploading","partUploadSuccessHandler","partUploadErrorHandler","push","currentFileSize","currentFileLastModified","oldSize","newSize","oldLastModified","newLastModified","conflicts","extension","substr","lastIndexOf"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;;;;;AAMA,OAAOA,IAAP,MAAiB,aAAjB;AACA,OAAOC,KAAP,MAAkB,cAAlB;AACA,SAASC,sCAAT,EAAiDC,8BAAjD,QAAuF,qBAAvF;AACA,SAASC,eAAT,QAAgC,sBAAhC;AACA,SAASC,MAAT,QAAuB,uBAAvB;AACA,OAAOC,WAAP,MAAwB,oBAAxB;AACA,OAAOC,YAAP,MAAyB,+BAAzB;AACA,SACIC,sBADJ,EAEIC,wCAFJ,EAGIC,0BAHJ,EAIIC,OAJJ,QAKO,iBALP;AAMA,OAAOC,YAAP,IACIC,mBADJ,EAEIC,oBAFJ,EAGIC,uBAHJ,EAIIC,sBAJJ,QAKO,gBALP;AAMA,OAAOC,YAAP,MAAyB,gBAAzB;AAKA;AAEA;AACA;AACA,IAAMC,wCAAwC,GAAG,2BAAjD;AACA,IAAMC,8CAA8C,GAAG,iCAAvD;AACA,IAAMC,yCAAyC,GAAG,4BAAlD;AACA,IAAMC,2CAA2C,GAAG,8BAApD;AACA,IAAMC,sCAAsC,GAAG,yBAA/C;AACA,IAAMC,+BAA+B,GAAG,kBAAxC;AACA,IAAMC,mDAAmD,GAAG,sCAA5D;AACA,IAAMC,2CAA2C,GAAG,8BAApD;IAEMC,c;;;;EAuDF;;;;;;EAMA,SAAA,cAAA,CAAYC,OAAZ,EAAiCC,MAAjC,EAA0D;IAAA,IAAA,KAAA;IAAA,eAAA,CAAA,IAAA,EAAA,cAAA,CAAA;IACtD,KAAA,GAAA,0BAAA,CAAA,IAAA,EAAA,eAAA,CAAA,cAAA,CAAA,CAAA,IAAA,CAAA,IAAA,EACID,OADJ,EAEI;MACIE,aAAa,EAAE,IADnB;MAEIC,UAAU,EAAE,IAFhB;MAGIC,SAAS,EAAE,IAHf;MAIIC,MAAM,EAAE,IAJZ;MAKIC,KAAK,EAAE,IALX;MAMIC,QAAQ,EAAE;IANd,CAFJ,EAUIN,MAVJ,CAAA,CAAA;IADsD,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,uCAAA,EA8JlB,UAAA,IAAA,EAAiD;MAAA,IAA9CwC,IAA8C,GAAA,IAAA,CAA9CA,IAA8C;MACrF,IAAI,CAACA,IAAD,IAAS,CAACA,IAAI,CAACC,UAAnB,EAA+B;QAC3B,OAAO,KAAA,CAAKC,gBAAL,CAAA,CAAP;MACH;MAED,IAAMC,QAAQ,GAAGH,IAAI,CAACC,UAALD,CAAgBI,KAAhBJ,CAAsB,GAAtBA,CAAjB,CALqF,CAMrF;;MACA,KAAA,CAAKK,UAAL,GAAA,EAAA,CAAA,MAAA,CAAqBF,QAAQ,CAAC,CAAD,CAA7B,EAAA,IAAA,CAAA,CAAA,MAAA,CAAqCA,QAAQ,CAAC,CAAD,CAA7C,CAAA;MACA,OAAO,KAAA,CAAKD,gBAAL,CAAA,CAAP;IACH,CAvKyD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,yBAAA,EAAA;IAAA,YAAA;MAAA,IAAA,KAAA,GAAA,iBAAA,EAAA;MAAA,mBAAA,CAAA,IAAA,CAgLhC,SAAA,OAAA,CAAOI,iBAAP,EAAA;QAAA,IAAA,SAAA,EAAA,gBAAA,EAAA,QAAA,EAAA,QAAA,EAAA,SAAA;QAAA,OAAA,mBAAA,CAAA,IAAA,CAAA,SAAA,QAAA,CAAA,QAAA,EAAA;UAAA,OAAA,CAAA,EAAA;YAAA,QAAA,QAAA,CAAA,IAAA,GAAA,QAAA,CAAA,IAAA;cAAA,KAAA,CAAA;gBAAA,IAAA,CAClB,KAAA,CAAKC,WAAL,CAAA,CADkB,EAAA;kBAAA,QAAA,CAAA,IAAA,GAAA,CAAA;kBAAA;gBAAA;gBAAA,OAAA,QAAA,CAAA,MAAA,CAAA,QAAA,CAAA;cAAA,KAAA,CAAA;gBAKhBC,SALgB,GAKJ,KAAA,CAAKC,qCAAL,CAA2CH,iBAA3C,CALI;gBAMlBI,gBANkB,GAAA,EAAA,CAAA,MAAA,CAMIF,SANJ,EAAA,wBAAA,CAAA,CAAA,CAQtB;;gBACA,IAAIE,gBAAgB,CAACC,QAAjBD,CAA0B,aAA1BA,CAAJ,EAA8C;kBAC1C,KAAA,CAAKlD,MAAL,CAAYoD,WAAZ,GAA0B,CAA1B;gBACH,CAXqB,CAatB;;gBACMC,QAdgB,GAcS;kBAC3BC,SAAS,EAAE,KAAA,CAAKhC,IAAL,CAAUY,IADM;kBAE3BqB,SAAS,EAAE,KAAA,CAAKzB;gBAFW,CAdT;gBAmBtB,IAAI,KAAA,CAAKD,MAAT,EAAiB;kBACbqB,gBAAgB,GAAGA,gBAAgB,CAACM,OAAjBN,CAAyB,iBAAzBA,EAAAA,EAAAA,CAAAA,MAAAA,CAA+C,KAAA,CAAKrB,MAApDqB,EAAAA,kBAAAA,CAAAA,CAAnBA;gBACH,CAFD,MAEO;kBACHG,QAAQ,CAACI,SAATJ,GAAqB,KAAA,CAAK9B,QAA1B8B;gBACH;gBAvBqB,QAAA,CAAA,IAAA,GAAA,CAAA;gBAAA,QAAA,CAAA,IAAA,GAAA,EAAA;gBAAA,OA0BK,KAAA,CAAKM,GAAL,CAASC,IAAT,CAAc;kBACjCC,GAAG,EAAEX,gBAD4B;kBAEjCV,IAAI,EAAEa;gBAF2B,CAAd,CA1BL;cAAA,KAAA,EAAA;gBA0BZK,QA1BY,GAAA,QAAA,CAAA,IAAA;gBA8BlB,KAAA,CAAKI,2BAAL,CAAiCJ,QAAQ,CAAClB,IAA1C,CAAA;gBA9BkB,QAAA,CAAA,IAAA,GAAA,EAAA;gBAAA;cAAA,KAAA,EAAA;gBAAA,QAAA,CAAA,IAAA,GAAA,EAAA;gBAAA,QAAA,CAAA,EAAA,GAAA,QAAA,CAAA,OAAA,CAAA,CAAA,CAAA,CAAA;gBAgCZuB,SAhCY,GAgCA,KAAA,CAAKC,gBAAL,CAAA,QAAA,CAAA,EAAA,CAhCA;gBAAA,IAAA,EAkCdD,SAAS,IAAIA,SAAS,CAACE,MAAVF,IAAoB,GAAjCA,IAAwCA,SAAS,CAACE,MAAVF,GAAmB,GAlC7C,CAAA,EAAA;kBAAA,QAAA,CAAA,IAAA,GAAA,EAAA;kBAAA;gBAAA;gBAmCd,KAAA,CAAKG,yBAAL,CAAA,QAAA,CAAA,EAAA,CAAA;gBAnCc,OAAA,QAAA,CAAA,MAAA,CAAA,QAAA,CAAA;cAAA,KAAA,EAAA;gBAAA,IAAA,EAyCdH,SAAS,IAAIA,SAAS,CAACE,MAAVF,KAAqB,GAAlCA,IAAyCA,SAAS,CAACI,IAAVJ,KAAmB,kBAzC9C,CAAA,EAAA;kBAAA,QAAA,CAAA,IAAA,GAAA,EAAA;kBAAA;gBAAA;gBA0Cd,KAAA,CAAKD,2BAAL,CAAiCC,SAAS,CAACK,YAAVL,CAAuBM,OAAxD,CAAA;gBA1Cc,OAAA,QAAA,CAAA,MAAA,CAAA,QAAA,CAAA;cAAA,KAAA,EAAA;gBAAA,IAAA,EA+CbN,SAAS,IACNA,SAAS,CAACE,MAAVF,KAAqBjF,0BADxBiF,IAEGA,SAAS,CAACI,IAAVJ,KAAmBlF,wCAFvB,IAGCkF,SAAS,CAACE,MAAVF,KAAqBjF,0BAArBiF,IACGA,SAAS,CAACI,IAAVJ,KAAmB,wCAnDT,CAAA,EAAA;kBAAA,QAAA,CAAA,IAAA,GAAA,EAAA;kBAAA;gBAAA;gBAqDd,KAAA,CAAKvC,aAAL,CAAmBuC,SAAnB,CAAA;gBArDc,OAAA,QAAA,CAAA,MAAA,CAAA,QAAA,CAAA;cAAA,KAAA,EAAA;gBAAA,IAAA,EAyDdA,SAAS,IAAIA,SAAS,CAACE,MAAVF,KAAqB,GAzDpB,CAAA,EAAA;kBAAA,QAAA,CAAA,IAAA,GAAA,EAAA;kBAAA;gBAAA;gBA0Dd,KAAA,CAAKO,eAAL,CAAqBP,SAArB,CAAA;gBACA,KAAA,CAAKQ,kBAAL,CAAA,CAAA;gBA3Dc,OAAA,QAAA,CAAA,MAAA,CAAA,QAAA,CAAA;cAAA,KAAA,EAAA;gBA+DlB;gBACA,KAAA,CAAKC,mBAAL,CAAA,QAAA,CAAA,EAAA,EAAgClF,wCAAhC,EAA0EmF,IAAI,CAACC,SAALD,CAAAA,QAAAA,CAAAA,EAAAA,CAA1E,CAAA;cAhEkB,KAAA,EAAA;cAAA,KAAA,KAAA;gBAAA,OAAA,QAAA,CAAA,IAAA,CAAA,CAAA;YAAA;UAAA;QAAA,CAAA,EAAA,OAAA,EAAA,IAAA,EAAA,CAAA,CAAA,CAAA,EAAA,EAAA,CAAA,CAAA,CAAA;MAAA,CAhLgC,CAAA,CAAA;MAAA,OAAA,UAAA,EAAA,EAAA;QAAA,OAAA,KAAA,CAAA,KAAA,CAAA,IAAA,EAAA,SAAA,CAAA;MAAA,CAAA;IAAA,CAAA,CAAA,CAAA,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,2BAAA,EA4P9B,UAACE,KAAD,EAAwB;MAChD,IAAI,KAAA,CAAK5B,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH;MAED,IAAI,KAAA,CAAK/B,gCAAL,GAAwC,KAAA,CAAKhB,MAAL,CAAY4E,OAAxD,EAAiE;QAC7D,KAAA,CAAKL,kBAAL,CAAA,CAAA;QACA;MACH;MAED,KAAA,CAAKM,UAAL,CAAgB,kDAAhB,CAAA;MACA,KAAA,CAAKL,mBAAL,CAAyBG,KAAzB,EAAgCpF,8CAAhC,EAAgFkF,IAAI,CAACC,SAALD,CAAeE,KAAfF,CAAhF,CAAA;IACH,CAxQyD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,gBAAA,EAAA;IAAA,iBAAA,EAAA;IAAA,mBAAA,CAAA,IAAA,CAuXzC,SAAA,QAAA,CAAA,EAAA;MAAA,IAAA,SAAA,EAAA,UAAA,EAAA,QAAA;MAAA,OAAA,mBAAA,CAAA,IAAA,CAAA,SAAA,SAAA,CAAA,SAAA,EAAA;QAAA,OAAA,CAAA,EAAA;UAAA,QAAA,SAAA,CAAA,IAAA,GAAA,SAAA,CAAA,IAAA;YAAA,KAAA,CAAA;cACPzB,SADO,GACK,KAAA,CAAKN,gBAAL,CAAA,CADL;cAEPqD,UAFO,GAAA,EAAA,CAAA,MAAA,CAES/C,SAFT,EAAA,yBAAA,CAAA,CAAA,MAAA,CAE4C,KAAA,CAAKsC,SAFjD,CAAA;cAAA,SAAA,CAAA,IAAA,GAAA,CAAA;cAAA,SAAA,CAAA,IAAA,GAAA,CAAA;cAAA,OAIc,KAAA,CAAK3B,GAAL,CAASqC,GAAT,CAAa;gBAAEnC,GAAG,EAAEkC;cAAP,CAAb,CAJd;YAAA,KAAA,CAAA;cAIHrC,QAJG,GAAA,SAAA,CAAA,IAAA;cAKT,KAAA,CAAKuC,wBAAL,CAA8BvC,QAAQ,CAAClB,IAAvC,CAAA;cALS,SAAA,CAAA,IAAA,GAAA,EAAA;cAAA;YAAA,KAAA,CAAA;cAAA,SAAA,CAAA,IAAA,GAAA,CAAA;cAAA,SAAA,CAAA,EAAA,GAAA,SAAA,CAAA,OAAA,CAAA,CAAA,CAAA,CAAA;cAOT,KAAA,CAAK0D,sBAAL,CAAA,SAAA,CAAA,EAAA,CAAA;YAPS,KAAA,EAAA;YAAA,KAAA,KAAA;cAAA,OAAA,SAAA,CAAA,IAAA,CAAA,CAAA;UAAA;QAAA;MAAA,CAAA,EAAA,QAAA,EAAA,IAAA,EAAA,CAAA,CAAA,CAAA,EAAA,CAAA,CAAA,CAAA,CAAA;IAAA,CAvXyC,CAAA,CAAA,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,0BAAA,EA6hB/B,UAACO,IAAD,EAA8B;MACrD,KAAA,CAAK5F,iBAAL,IAA0B,CAA1B;MACA,KAAA,CAAKC,gBAAL,IAAyB,CAAzB;MACA,KAAA,CAAK6G,cAAL,CAAoBlB,IAAI,CAACmB,aAAzB,EAAwC,KAAA,CAAK3G,QAA7C,CAAA;MACA,KAAA,CAAK2E,gBAAL,CAAA,CAAA;IACH,CAliByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,wBAAA,EA4iBjC,UAACjB,KAAD,EAAekD,SAAf,EAA2C;MAChE,KAAA,CAAKrD,mBAAL,CAAyBG,KAAzB,EAAgClF,2CAAhC,EAA6EoI,SAA7E,CAAA,CADgE,CAEhE;MACA;;MACA,IAAI,KAAA,CAAKzG,yBAAT,EAAoC;QAChC;QACA,IAAI0G,eAAe,GAAG,KAAA,CAAK/G,wBAA3B;QACA,OAAO,KAAA,CAAKF,iBAAL,GAAyB,CAAhC,EAAmC;UAC/B,IAAM4F,IAAI,GAAG,KAAA,CAAKlG,KAAL,CAAWuH,eAAX,CAAb;UACA,IAAIrB,IAAI,IAAIA,IAAI,CAACsB,KAALtB,KAAevH,oBAA3B,EAAiD;YAC7CuH,IAAI,CAACE,KAALF,CAAAA,CAAAA;YACAA,IAAI,CAACuB,KAALvB,CAAAA,CAAAA;YAEA,KAAA,CAAK5F,iBAAL,IAA0B,CAA1B;YACA,KAAA,CAAKD,mBAAL,IAA4B,CAA5B;UACH;UACDkH,eAAe,IAAI,CAAnBA;QACH;MACJ;IACJ,CA/jByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,gBAAA,EAykBzC,UAACG,iBAAD,EAA4BC,gBAA5B,EAA+D;MAC5E,IAAI,KAAA,CAAKnF,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH;MAED,KAAA,CAAKtC,kBAAL,IAA2ByH,gBAAgB,GAAGD,iBAA9C;MACA,KAAA,CAAKxG,gBAAL,CAAsB;QAClB0G,MAAM,EAAE,KAAA,CAAK1H,kBADK;QAElB2H,KAAK,EAAE,KAAA,CAAK9G,IAAL,CAAUY;MAFC,CAAtB,CAAA;IAIH,CAnlByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,kBAAA,EA4lBvC,YAAY;MAC3B,IAAI,KAAA,CAAKmG,+BAAL,CAAA,CAAJ,EAA4C;QACxC;MACH;MAED,IAAI,KAAA,CAAKvH,gBAAL,KAA0B,KAAA,CAAKP,KAAL,CAAW+H,MAArC,IAA+C,KAAA,CAAK9H,QAAxD,EAAkE;QAC9D,KAAA,CAAK+H,aAAL,CAAA,CAAA;QACA;MACH;MAED,KAAA,CAAKC,8BAAL,CAAA,CAAA;MAEA,OAAO,KAAA,CAAKC,uBAAL,CAAA,CAAP,EAAuC;QACnC,KAAA,CAAKC,cAAL,CAAA,CAAA;MACH;MAED,IAAI,KAAA,CAAKC,8BAAL,CAAA,CAAJ,EAA2C;QACvC,KAAA,CAAKC,wBAAL,CAAA,CAAA;MACH;IACJ,CA/mByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,iBAAA,EAysBxC,UAACgC,KAAD,EAAmB;MACjC,IAAI,KAAA,CAAK7H,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH;MAHgC,IAKzBP,IALyB,GAKhBoI,KALgB,CAKzBpI,IALyB;MAMjC,IAAIA,IAAI,CAACqI,IAALrI,KAAc,UAAlB,EAA8B;QAC1B,KAAA,CAAK7B,uBAAL,IAAgC,CAAhC;QAD0B,IAElB8F,IAFkB,GAETjE,IAFS,CAElBiE,IAFkB;QAG1B,KAAA,CAAKlG,KAAL,CAAWkG,IAAI,CAACqE,KAAhB,CAAA,CAAuBP,MAAvB,CAA8BQ,cAA9B,GAA+CvI,IAAI,CAACwI,QAApD;QACA,KAAA,CAAKpF,gBAAL,CAAA,CAAA;MACH,CALD,MAKO,IAAIpD,IAAI,CAACqI,IAALrI,KAAc,MAAlB,EAA0B;QAC7B,KAAA,CAAKhC,QAAL,GAAgB9B,WAAW,CAAC8D,IAAI,CAACyI,IAAN,CAA3B;QACA,KAAA,CAAK7I,UAAL,CAAgBqF,SAAhB,CAAA,CAAA;QACA,KAAA,CAAK7B,gBAAL,CAAA,CAAA;MACH,CAJM,MAIA,IAAIpD,IAAI,CAACqI,IAALrI,KAAc,OAAlB,EAA2B;QAC9B,KAAA,CAAKgC,mBAAL,CAAyB,IAAzB,EAA+B7E,+BAA/B,EAAgE8E,IAAI,CAACC,SAALD,CAAejC,IAAfiC,CAAhE,CAAA;MACH;IACJ,CA3tByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,kBAAA,EAquBvC,UAACgC,IAAD,EAAqBgD,MAArB,EAAmD;MAClE,IAAI,KAAA,CAAK1G,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH,CAHiE,CAKlE;;MACA,IAAMmI,eAAe,GAAG;QACpBJ,KAAK,EAAErE,IAAI,CAACqE,KADQ;QAEpB5B,MAAM,EAAEzC,IAAI,CAACyC,MAFO;QAGpBhH,IAAI,EAAEuE,IAAI,CAACxF;MAHS,CAAxB;MAKA,KAAA,CAAKmB,UAAL,CAAgB+I,WAAhB,CACI;QACI1E,IAAI,EAAEyE,eADV;QAEIE,QAAQ,EAAE,KAAA,CAAK9J,IAAL,CAAUY,IAFxB;QAGImJ,YAAY,EAAE5B;MAHlB,CADJ,EAMI,CAACA,MAAD,CANJ,CAMc;MANd,CAAA;;MAQA,KAAA,CAAK5E,UAAL,CAAA,uBAAA,CAAA,MAAA,CAAwCJ,IAAI,CAACC,SAALD,CAAegC,IAAfhC,CAAxC,EAAA,IAAA,CAAA,CAAA;IACH,CAzvByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,mBAAA,EAmwBtC,UAACE,KAAD,EAAe8B,IAAf,EAA4C;MAC5D,KAAA,CAAK5B,UAAL,CAAA,kCAAA,CAAA,MAAA,CAAmDJ,IAAI,CAACC,SAALD,CAAegC,IAAfhC,CAAnD,EAAA,IAAA,CAAA,CAAA,MAAA,CAA4EA,IAAI,CAACC,SAALD,CAAeE,KAAfF,CAA5E,CAAA,CAAA,CAD4D,CAG5D;MACA;MACA;MACA;;MACA,IAAIE,KAAK,CAAC5C,IAAN4C,KAAe,eAAfA,IAAkCA,KAAK,CAAC5C,IAAN4C,KAAe,eAArD,EAAsE;QAClE,KAAA,CAAKH,mBAAL,CAAyB,IAAzB,EAA+B5E,mDAA/B,EAAoF6E,IAAI,CAACC,SAALD,CAAeE,KAAfF,CAApF,CAAA;QACA;MACH;MAED,IAAI,KAAA,CAAK4D,+BAAL,CAAA,CAAJ,EAA4C;QACxC;MACH;MAED,IAAI5B,IAAI,CAAC6E,yBAAL7E,IAAkC,KAAA,CAAKzG,MAAL,CAAY4E,OAAlD,EAA2D;QACvD,KAAA,CAAKJ,mBAAL,CAAyB,IAAzB,EAA+B3E,2CAA/B,EAA4E4E,IAAI,CAACC,SAALD,CAAeE,KAAfF,CAA5E,CAAA;QACA;MACH;MAED,IAAMK,YAAY,GAAGvG,8BAA8B,CAC/C,KAAA,CAAKyB,MAAL,CAAY+E,mBADmC,EAE/C,KAAA,CAAK/E,MAAL,CAAYgF,eAFmC,EAG/CyB,IAAI,CAAC6E,yBAH0C,CAAnD;MAKA7E,IAAI,CAAC6E,yBAAL7E,IAAkC,CAAlCA;MACA,KAAA,CAAK5B,UAAL,CAAA,gCAAA,CAAA,MAAA,CAAiDJ,IAAI,CAACC,SAALD,CAAegC,IAAfhC,CAAjD,EAAA,MAAA,CAAA,CAAA,MAAA,CAA4EK,YAA5E,EAAA,KAAA,CAAA,CAAA;MAEAI,UAAU,CAAC,YAAM;QACb,KAAA,CAAK6D,oBAAL,CAA0BtC,IAA1B,CAAA;MACH,CAFS,EAEP3B,YAFO,CAAVI;IAGH,CAnyByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,eAAA,EA2yB1C,YAAY;MACxB,IAAI,KAAA,CAAKnC,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH;MAED,IAAMwI,KAAK,GAAG;QACVC,iBAAiB,EAAE,CADT;QAEVC,mBAAmB,EAAE,CAFX;QAGVC,mBAAmB,EAAE,CAHX;QAIVC,mBAAmB,EAAE;MAJX,CAAd;MAOA,IAAMnJ,IAAI,GAAG;QACTjC,KAAK,EAAE,KAAA,CAAKA,KAAL,CACFqL,GADE,CACE,UAAA,IAAI,EAAI;UACTL,KAAK,CAACC,iBAAND,IAA2B9E,IAAI,CAAC8D,MAAL9D,CAAYgE,QAAvCc;UACAA,KAAK,CAACE,mBAANF,IAA6B9E,IAAI,CAAC8D,MAAL9D,CAAYiE,gBAAzCa;UACAA,KAAK,CAACG,mBAANH,IAA6B9E,IAAI,CAAC8D,MAAL9D,CAAYsE,cAAzCQ;UACAA,KAAK,CAACI,mBAANJ,IAA6B9E,IAAI,CAAC8D,MAAL9D,CAAYoF,UAAzCN;UACA,OAAO9E,IAAI,CAACqF,OAALrF,CAAAA,CAAP;QACH,CAPE,CAAA,CAQFsF,IARE,CAQG,UAACC,KAAD,EAAQC,KAAR,EAAA;UAAA,OAAkBD,KAAK,CAAC9C,MAAN8C,GAAeC,KAAK,CAAC/C,MAAvC;QAAA,CARH,CADE;QAUTgD,UAAU,EAAE,CAAA;MAVH,CAAb;MAaA,IAAMC,gBAAgB,GAAG7N,sCAAsC,CAAC,KAAA,CAAKgD,IAAN,CAA/D;MACA,IAAI6K,gBAAJ,EAAsB;QAClB3J,IAAI,CAAC0J,UAAL1J,CAAgB4J,mBAAhB5J,GAAsC2J,gBAAtC3J;MACH;MACD,IAAI,KAAA,CAAKR,eAAT,EAA0B;QACtBQ,IAAI,CAAC0J,UAAL1J,CAAgB6J,WAAhB7J,GAA8B,KAAA,CAAKR,eAAnCQ;MACH;MAED,IAAM8J,eAAe,GAAG;QACpBC,kBAAkB,EAAEC,IAAI,CAACC,KAALD,CAAWjB,KAAK,CAACC,iBAAND,GAA0B,KAAA,CAAKhL,KAAL,CAAW+H,MAAhDkE,CADA;QAEpBE,oBAAoB,EAAEF,IAAI,CAACC,KAALD,CAAWjB,KAAK,CAACE,mBAANF,GAA4B,KAAA,CAAKhL,KAAL,CAAW+H,MAAlDkE,CAFF;QAGpBG,oBAAoB,EAAEH,IAAI,CAACC,KAALD,CAAWjB,KAAK,CAACG,mBAANH,GAA4B,KAAA,CAAKhL,KAAL,CAAW+H,MAAlDkE,CAHF;QAIpBI,oBAAoB,EAAEJ,IAAI,CAACC,KAALD,CAAWjB,KAAK,CAACI,mBAANJ,GAA4B,KAAA,CAAKhL,KAAL,CAAW+H,MAAlDkE;MAJF,CAAxB,CAjCwB,CAwCxB;;MACA,IAAMhM,QAAgB,GAAI,KAAA,CAAKA,QAA/B;MACA,IAAM4F,OAAO,GAAG;QACZyG,MAAM,EAAA,MAAA,CAAA,MAAA,CAASrM,QAAT,CADM;QAEZ,yBAAA,EAA2BiE,IAAI,CAACC,SAALD,CAAe6H,eAAf7H;MAFf,CAAhB;MAKA,KAAA,CAAKd,GAAL,CACKC,IADL,CACU;QAAEC,GAAG,EAAE,KAAA,CAAK0B,gBAAL,CAAsBnF,MAA7B;QAAqCoC,IAAI,EAAJA,IAArC;QAA2C4D,OAAO,EAAPA;MAA3C,CADV,CAAA,CAEKmB,IAFL,CAEU,KAAA,CAAKuF,2BAFf,CAAA,CAGKtF,KAHL,CAGW,KAAA,CAAKuF,yBAHhB,CAAA;IAIH,CA91ByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,6BAAA,EAu2B5B,UAACrJ,QAAD,EAA4B;MACtD,IAAI,KAAA,CAAKX,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH;MAHqD,IAK9CkB,MAL8C,GAK7BP,QAL6B,CAK9CO,MAL8C;QAKtCzB,IALsC,GAK7BkB,QAL6B,CAKtClB,IALsC;MAOtD,IAAIyB,MAAM,KAAK,GAAf,EAAoB;QAChB,KAAA,CAAK+I,kBAAL,CAAwBtJ,QAAxB,CAAA;QACA;MACH;MAVqD,IAYhDuJ,OAZgD,GAYpCzK,IAZoC,CAYhDyK,OAZgD,CAAA,CAatD;MACA;;MACA,IAAI,CAACA,OAAD,IAAYzK,IAAI,CAAC2C,EAArB,EAAyB;QACrB8H,OAAO,GAAG,CAACzK,IAAD,CAAVyK;MACH;MAED,KAAA,CAAK9F,OAAL,CAAA,CAAA;MAEA,IAAI,KAAA,CAAKzF,eAAL,IAAwBuL,OAA5B,EAAqC;QACjC,KAAA,CAAKvL,eAAL,CAAqBuL,OAArB,CAAA;MACH;IACJ,CA/3ByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,2BAAA,EAy4B9B,UAACtI,KAAD,EAAyB;MACjD,IAAI,KAAA,CAAK5B,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH;MAHgD,IAKzCW,QALyC,GAK5BiB,KAL4B,CAKzCjB,QALyC;MAOjD,IAAI,CAACA,QAAL,EAAe;QACX;QACA,KAAA,CAAKwJ,YAAL,CAAkBvI,KAAlB,CAAA;QACA;MACH;MAED,IAAI,KAAA,CAAKzD,gBAAL,IAAyB,KAAA,CAAKlB,MAAL,CAAY4E,OAAzC,EAAkD;QAC9C,KAAA,CAAKC,UAAL,CAAgB,0CAAhB,CAAA;QACA,KAAA,CAAKL,mBAAL,CAAyBG,KAAzB,EAAgCjF,sCAAhC,EAAwE+E,IAAI,CAACC,SAALD,CAAeE,KAAfF,CAAxE,CAAA;QACA;MACH;MAED,KAAA,CAAKuI,kBAAL,CAAwBtJ,QAAxB,CAAA;IACH,CA75ByD,CAAA;IAAA,eAAA,CAAA,sBAAA,CAAA,KAAA,CAAA,EAAA,sBAAA,EA2/BnC,YAAA;MAAA,OAAc,KAAA,CAAK7C,iBAAnB;IAAA,CA3/BmC,CAAA;IAatD,KAAA,CAAKN,KAAL,GAAa,EAAb;IACA,KAAA,CAAKR,OAAL,GAAeA,OAAf;IACA,KAAA,CAAKS,QAAL,GAAgB,IAAhB;IACA,KAAA,CAAKC,kBAAL,GAA0B,CAA1B;IACA,KAAA,CAAKC,kBAAL,GAA0B,CAA1B,CAjBsD,CAiBzB;;IAC7B,KAAA,CAAKC,uBAAL,GAA+B,CAA/B,CAlBsD,CAkBpB;;IAClC,KAAA,CAAKC,mBAAL,GAA2B,CAA3B,CAnBsD,CAmBxB;;IAC9B,KAAA,CAAKC,iBAAL,GAAyB,CAAzB,CApBsD,CAoB1B;;IAC5B,KAAA,CAAKC,gBAAL,GAAwB,CAAxB,CArBsD,CAqB3B;;IAC3B,KAAA,CAAKC,wBAAL,GAAgC,CAAhC,CAtBsD,CAsBnB;;IACnC,KAAA,CAAKC,gCAAL,GAAwC,CAAxC;IACA,KAAA,CAAKC,QAAL,GAAgB,CAAhB;IACA,KAAA,CAAKC,gBAAL,GAAwB,CAAxB;IACA,KAAA,CAAKC,QAAL,GAAgB,IAAhB;IACA,KAAA,CAAKC,yBAAL,GAAiC,KAAjC;IACA,KAAA,CAAKC,gBAAL,GAAwB,CAAxB;IA5BsD,OAAA,KAAA;EA6BzD;EAED;;;;;;4BAGQ;MACJ,IAAA,CAAKd,KAAL,GAAa,EAAb;MACA,IAAA,CAAKC,QAAL,GAAgB,IAAhB;MACA,IAAA,CAAKC,kBAAL,GAA0B,CAA1B;MACA,IAAA,CAAKC,kBAAL,GAA0B,CAA1B,CAJI,CAIyB;;MAC7B,IAAA,CAAKC,uBAAL,GAA+B,CAA/B,CALI,CAK8B;;MAClC,IAAA,CAAKC,mBAAL,GAA2B,CAA3B,CANI,CAM0B;;MAC9B,IAAA,CAAKC,iBAAL,GAAyB,CAAzB,CAPI,CAOwB;;MAC5B,IAAA,CAAKC,gBAAL,GAAwB,CAAxB,CARI,CAQuB;;MAC3B,IAAA,CAAKC,wBAAL,GAAgC,CAAhC,CATI,CAS+B;;MACnC,IAAA,CAAKC,gCAAL,GAAwC,CAAxC;MACA,IAAA,CAAKC,QAAL,GAAgB,CAAhB;MACA,IAAA,CAAKC,gBAAL,GAAwB,CAAxB;MACA,IAAA,CAAKG,gBAAL,GAAwB,CAAxB;IACH;IAED;;;;;;;;;;;;;;;;uCAgCS;MAAA,IAjBLC,IAiBK,GAAA,KAAA,CAjBLA,IAiBK;QAhBLC,QAgBK,GAAA,KAAA,CAhBLA,QAgBK;QAfLC,aAeK,GAAA,KAAA,CAfLA,aAeK;QAdLC,gBAcK,GAAA,KAAA,CAdLA,gBAcK;QAbLC,eAaK,GAAA,KAAA,CAbLA,eAaK;QAAA,eAAA,GAAA,KAAA,CAZLC,SAYK;QAZLA,SAYK,GAAA,eAAA,KAAA,KAAA,CAAA,GAZO,IAYP,GAAA,eAAA;QAXLC,gBAWK,GAAA,KAAA,CAXLA,gBAWK;QAVLC,MAUK,GAAA,KAAA,CAVLA,MAUK;MACL,IAAA,CAAKP,IAAL,GAAYA,IAAZ;MACA,IAAA,CAAKQ,QAAL,GAAgB,IAAA,CAAKR,IAAL,CAAUS,IAA1B;MACA,IAAA,CAAKR,QAAL,GAAgBA,QAAhB;MACA,IAAA,CAAKC,aAAL,GAAqBA,aAAa,IAAIpD,IAAtC;MACA,IAAA,CAAKqD,gBAAL,GAAwBA,gBAAgB,IAAIrD,IAA5C;MACA,IAAA,CAAKsD,eAAL,GAAuBA,eAAe,IAAItD,IAA1C;MACA,IAAA,CAAKuD,SAAL,GAAiBA,SAAjB;MACA,IAAA,CAAKC,gBAAL,GAAwBA,gBAAxB;MACA,IAAA,CAAKC,MAAL,GAAcA,MAAd;IACH;IAED;;;;;;;;;;;;;;;kCAiCS;MAAA,IAnBLP,IAmBK,GAAA,KAAA,CAnBLA,IAmBK;QAlBLU,eAkBK,GAAA,KAAA,CAlBLA,eAkBK;QAjBLT,QAiBK,GAAA,KAAA,CAjBLA,QAiBK;QAhBLC,aAgBK,GAAA,KAAA,CAhBLA,aAgBK;QAfLC,gBAeK,GAAA,KAAA,CAfLA,gBAeK;QAdLC,eAcK,GAAA,KAAA,CAdLA,eAcK;QAAA,eAAA,GAAA,KAAA,CAbLC,SAaK;QAbLA,SAaK,GAAA,eAAA,KAAA,KAAA,CAAA,GAbO,IAaP,GAAA,eAAA;QAZLC,gBAYK,GAAA,KAAA,CAZLA,gBAYK;QAXLC,MAWK,GAAA,KAAA,CAXLA,MAWK;MACL,IAAA,CAAKP,IAAL,GAAYA,IAAZ;MACA,IAAA,CAAKQ,QAAL,GAAgB,IAAA,CAAKR,IAAL,CAAUS,IAA1B,CAFK,CAGL;MACA;;MACA,IAAA,CAAKE,eAAL,GAAuB,IAAA,CAAKX,IAAL,CAAUY,IAAjC;MACA,IAAA,CAAKC,uBAAL,GAA+B7D,sCAAsC,CAAC,IAAA,CAAKgD,IAAN,CAArE;MACA,IAAA,CAAKC,QAAL,GAAgBA,QAAhB;MACA,IAAA,CAAKC,aAAL,GAAqBA,aAAa,IAAIpD,IAAtC;MACA,IAAA,CAAKqD,gBAAL,GAAwBA,gBAAgB,IAAIrD,IAA5C;MACA,IAAA,CAAKsD,eAAL,GAAuBA,eAAe,IAAItD,IAA1C;MAEA,IAAA,CAAKgE,UAAL,GAAkBzD,YAAY,CAAA,CAA9B;MACA,IAAA,CAAKyD,UAAL,CAAgBC,gBAAhB,CAAiC,SAAjC,EAA4C,IAAA,CAAKC,eAAjD,CAAA;MAEA,IAAA,CAAKV,gBAAL,GAAwBA,gBAAxB;MACA,IAAA,CAAKD,SAAL,GAAiBA,SAAjB;MACA,IAAA,CAAKE,MAAL,GAAcA,MAAd;MACA,IAAA,CAAKG,eAAL,GAAuBA,eAAvB;MAEA,IAAA,CAAKO,oBAAL,CAAA,CAAA;IACH;IAED;;;;;;;;;;IAoHA;;;;;;yCAM2B;MACvB,IAAMuC,YAAY,GAAGvG,8BAA8B,CAC/C,IAAA,CAAKyB,MAAL,CAAY+E,mBADmC,EAE/C,IAAA,CAAK/E,MAAL,CAAYgF,eAFmC,EAG/C,IAAA,CAAKhE,gCAH0C,CAAnD;MAKA,IAAA,CAAKA,gCAAL,IAAyC,CAAzC;MACA,IAAA,CAAK6D,UAAL,CAAA,6BAAA,CAAA,MAAA,CAA8CC,YAA9C,EAAA,KAAA,CAAA,CAAA;MACA,IAAA,CAAKG,oBAAL,GAA4BC,UAAU,CAAC,IAAA,CAAK3C,oBAAN,EAA4BuC,YAA5B,CAAtC;IACH;IAED;;;;;;;;;gDAO4BtC,I,EAAiB;MACzC,IAAI,IAAA,CAAKO,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH;MAHwC,IAKjCoC,EALiC,GAKI3C,IALJ,CAKjC2C,EALiC;QAK7BC,SAL6B,GAKI5C,IALJ,CAK7B4C,SAL6B;QAKlBC,iBALkB,GAKI7C,IALJ,CAKlB6C,iBALkB;MAOzC,IAAA,CAAKC,SAAL,GAAiBH,EAAjB;MACA,IAAA,CAAKlE,QAAL,GAAgBmE,SAAhB;MACA,IAAA,CAAKG,gBAAL,GAAA,aAAA,CAAA,CAAA,CAAA,EACO,IAAA,CAAKA,gBADZ,EAAA;QAEIrF,UAAU,EAAEmF,iBAAiB,CAACG,WAFlC;QAGIrF,SAAS,EAAEkF,iBAAiB,CAACI,UAHjC;QAIIrF,MAAM,EAAEiF,iBAAiB,CAACjF,MAJ9B;QAKIC,KAAK,EAAEgF,iBAAiB,CAAChF,KAL7B;QAMIC,QAAQ,EAAE+E,iBAAiB,CAACK;MANhC,CAAA,CAAA;MASA,IAAA,CAAKC,aAAL,CAAA,CAAA;MACA,IAAA,CAAKC,gBAAL,CAAA,CAAA;IACH;IAED;;;;;;;;;;;;;;;;;kCAmCS;MAAA,IAnBLtE,IAmBK,GAAA,KAAA,CAnBLA,IAmBK;QAlBLC,QAkBK,GAAA,KAAA,CAlBLA,QAkBK;QAjBLC,aAiBK,GAAA,KAAA,CAjBLA,aAiBK;QAhBLC,gBAgBK,GAAA,KAAA,CAhBLA,gBAgBK;QAfL6D,SAeK,GAAA,KAAA,CAfLA,SAeK;QAdL5D,eAcK,GAAA,KAAA,CAdLA,eAcK;QAAA,eAAA,GAAA,KAAA,CAbLC,SAaK;QAbLA,SAaK,GAAA,eAAA,KAAA,KAAA,CAAA,GAbO,IAaP,GAAA,eAAA;QAZLC,gBAYK,GAAA,KAAA,CAZLA,gBAYK;QAXLC,MAWK,GAAA,KAAA,CAXLA,MAWK;MACL,IAAA,CAAKgE,WAAL,CAAiB;QACbvE,IAAI,EAAJA,IADa;QAEbC,QAAQ,EAARA,QAFa;QAGbC,aAAa,EAAbA,aAHa;QAIbC,gBAAgB,EAAhBA,gBAJa;QAKbC,eAAe,EAAfA,eALa;QAMbE,gBAAgB,EAAhBA,gBANa;QAObD,SAAS,EAATA,SAPa;QAQbE,MAAM,EAANA;MARa,CAAjB,CAAA;MAUA,IAAA,CAAKyD,SAAL,GAAiBA,SAAjB;MAEA,IAAI,CAAC,IAAA,CAAKlD,UAAV,EAAsB;QAClB,IAAA,CAAKA,UAAL,GAAkBzD,YAAY,CAAA,CAA9B;MACH;MACD,IAAA,CAAKyD,UAAL,CAAgBC,gBAAhB,CAAiC,SAAjC,EAA4C,IAAA,CAAKC,eAAjD,CAAA;MAEA,IAAA,CAAKwD,cAAL,CAAA,CAAA;IACH;IAED;;;;;;;;;IAkBA;;;;;;;6CAOyBtD,I,EAAiB;MAAA,IAC9B4C,SAD8B,GACG5C,IADH,CAC9B4C,SAD8B;QACnBC,iBADmB,GACG7C,IADH,CACnB6C,iBADmB,CAAA,CAGtC;;MACA,IAAA,CAAKpE,QAAL,GAAgBmE,SAAhB;MACA,IAAA,CAAKG,gBAAL,GAAA,aAAA,CAAA,CAAA,CAAA,EACO,IAAA,CAAKA,gBADZ,EAAA;QAEIrF,UAAU,EAAEmF,iBAAiB,CAACG,WAFlC;QAGIrF,SAAS,EAAEkF,iBAAiB,CAACI,UAHjC;QAIIrF,MAAM,EAAEiF,iBAAiB,CAACjF,MAJ9B;QAKIC,KAAK,EAAEgF,iBAAiB,CAAChF,KAL7B;QAMIC,QAAQ,EAAE+E,iBAAiB,CAACK;MANhC,CAAA,CAAA;MASA,IAAA,CAAKE,gBAAL,CAAA,CAAA;IACH;IAED;;;;;;;;;2CAOuBjB,K,EAAoB;MACvC,IAAI,IAAA,CAAK5B,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH;MAED,IAAMgB,SAAS,GAAG,IAAA,CAAKC,gBAAL,CAAsBW,KAAtB,CAAlB;MACA,IAAI,IAAA,CAAKtD,gBAAL,GAAwB,IAAA,CAAKrB,MAAL,CAAY4E,OAAxC,EAAiD;QAC7C,IAAA,CAAKpD,aAAL,CAAmBuC,SAAnB,CAAA;QACA;MACH;MAED,IAAIA,SAAS,IAAIA,SAAS,CAACE,MAAVF,KAAqB,GAAtC,EAA2C;QACvC,IAAIoC,YAAY,GAAGvH,sBAAnB;QACA,IAAImF,SAAS,CAACqC,OAAd,EAAuB;UACnB,IAAMC,aAAa,GAAGC,QAAQ,CAC1BvC,SAAS,CAACqC,OAAVrC,CAAkB,aAAlBA,CAAAA,IAAoCA,SAAS,CAACqC,OAAVrC,CAAkBiC,GAAlBjC,CAAsB,aAAtBA,CADV,EAE1B,EAF0B,CAA9B;UAIA,IAAI,CAAC1F,KAAK,CAACgI,aAAD,CAAV,EAA2B;YACvBF,YAAY,GAAGE,aAAa,GAAGtH,OAA/BoH;UACH;QACJ;QACD,IAAA,CAAKI,YAAL,GAAoBrB,UAAU,CAAC,IAAA,CAAKY,cAAN,EAAsBK,YAAtB,CAA9B;QACA,IAAA,CAAK9E,gBAAL,IAAyB,CAAzB;MACH,CAbD,MAaO,IAAI0C,SAAS,IAAIA,SAAS,CAACE,MAAVF,IAAoB,GAAjCA,IAAwCA,SAAS,CAACE,MAAVF,GAAmB,GAA/D,EAAoE;QACvE;QACA,IAAA,CAAKxD,KAAL,CAAWiG,OAAX,CAAmB,UAAA,IAAI,EAAI;UACvBC,IAAI,CAACC,MAALD,CAAAA,CAAAA;QACH,CAFD,CAAA;QAGA,IAAA,CAAKE,KAAL,CAAA,CAAA,CALuE,CAOvE;;QACAC,YAAY,CAAC,IAAA,CAAK3B,oBAAN,CAAZ2B;QACAA,YAAY,CAAC,IAAA,CAAKC,oBAAN,CAAZD;QACA,IAAA,CAAKE,YAAL,CAAA,CAAA,CAVuE,CAWvE;;QACA,IAAMC,aAAqB,GAAG;UAC1BzF,IAAI,EAAE,IAAA,CAAKA,IADe;UAE1BC,QAAQ,EAAE,IAAA,CAAKA,QAFW;UAG1BC,aAAa,EAAE,IAAA,CAAKA,aAHM;UAI1BC,gBAAgB,EAAE,IAAA,CAAKA,gBAJG;UAK1BC,eAAe,EAAE,IAAA,CAAKA,eALI;UAM1BC,SAAS,EAAE,IAAA,CAAKA,SANU;UAO1BE,MAAM,EAAE,IAAA,CAAKA;QAPa,CAA9B;QASA,IAAA,CAAKmF,MAAL,CAAYD,aAAZ,CAAA;MACH,CAtBM,MAsBA;QACH;QACA;QACA,IAAA,CAAKR,YAAL,GAAoBrB,UAAU,CAAC,IAAA,CAAKY,cAAN,EAAsB,IAAA,CAAA,GAAA,CAAA,CAAA,EAAK,IAAA,CAAKzE,gBAAV,CAAA,GAA6BtC,OAAnD,CAA9B;QACA,IAAA,CAAKsC,gBAAL,IAAyB,CAAzB;MACH;IACJ;IAED;;;;;;;;;;;;;;iDAU0BsD,K,EAAesC,Y,EAAsBC,U;;;;;;;gBAC3D,IAAI,CAAC,IAAA,CAAK9F,yBAAV,EAAqC;kBACjC,IAAA,CAAK+F,OAAL,CAAA,CAAA;gBACH;gBACKpD,S,GAAY,IAAA,CAAKC,gBAAL,CAAsBW,KAAtB,C;gBAClB,IAAA,CAAKnD,aAAL,CAAmBuC,SAAnB,CAAA;;oBAGS,IAAA,CAAKwB,gBAAL,CAAsBjF,Q;;;;sBACjB,IAAI8G,KAAJ,CAAU,6BAAV,C;;;uBAGJ5I,eAAe,CACjB,UAAC6I,OAAD,EAAoBC,MAApB,EAA+C;kBAC3C,MAAI,CAAChH,QAAL,CAAc2G,YAAd,EAA4BC,UAA5B,CAAA,CACKK,IADL,CACUF,OADV,CAAA,CAEKG,KAFL,CAEWF,MAFX,CAAA;gBAGH,CALgB,EAMjB,IAAA,CAAKtH,MAAL,CAAY4E,OANK,EAOjB,IAAA,CAAK5E,MAAL,CAAY+E,mBAPK,C;;gBASrB,IAAI,CAAC,IAAA,CAAK3D,yBAAV,EAAqC;kBACjC,IAAA,CAAK0F,YAAL,CAAA,CAAA;gBACH;;;;;;gBAED,IAAI,CAAC,IAAA,CAAK1F,yBAAV,EAAqC;kBACjC,IAAA,CAAK0F,YAAL,CAAA,CAAA;gBACH;;;;;;;;;;;;;IAIT;;;;;;;;mCAMqB;MAAA,IAAA,MAAA,GAAA,IAAA;MACjB,IAAI,IAAA,CAAK1E,UAAT,EAAqB;QACjB,IAAA,CAAKA,UAAL,CAAgBqF,SAAhB,CAAA,CAAA;MACH;MAED,IAAI,IAAA,CAAKlC,gBAAL,CAAsBlF,KAAtB,IAA+B,IAAA,CAAKiF,SAAxC,EAAmD;QAC/C,IAAA,CAAK3B,GAAL,CACK+D,MADL,CACY;UACJ7D,GAAG,EAAE,IAAA,CAAK0B,gBAAL,CAAsBlF;QADvB,CADZ,CAAA,CAIKkH,IAJL,CAIU,YAAM;UACR,MAAI,CAACjC,SAAL,GAAiB,EAAjB;QACH,CANL,CAAA;MAOH;IACJ;IAED;;;;;;;;;IA2FA;;;;;;;qDAO0C;MACtC,OACI,CAAC,IAAA,CAAKvC,WAAL,CAAA,CAAD,IACA,IAAA,CAAKpC,uBAAL,KAAiC,CADjC,IAEA,IAAA,CAAKD,kBAAL,GAA0B,CAF1B,IAGA,IAAA,CAAKE,mBAAL,GAA2B,IAAA,CAAKZ,MAAL,CAAY6I,eAJ3C;IAMH;IAED;;;;;;;+CAMiC;MAC7B,KAAK,IAAIC,CAAC,GAAG,IAAA,CAAK/H,wBAAlB,EAA4C+H,CAAC,GAAG,IAAA,CAAKvI,KAAL,CAAW+H,MAA3D,EAAmEQ,CAAC,IAAI,CAAxE,EAA2E;QACvE,IAAMrC,IAAI,GAAG,IAAA,CAAKlG,KAAL,CAAWuI,CAAX,CAAb;QACA,IAAIrC,IAAI,CAACsB,KAALtB,KAAerH,sBAAnB,EAA2C;UACvC;UACA;UACA,IAAA,CAAKsB,kBAAL,IAA2B,CAA3B;UACA,IAAA,CAAKC,uBAAL,IAAgC,CAAhC;UACA,IAAA,CAAKoI,oBAAL,CAA0BtC,IAA1B,CAAA;UACA;QACH;MACJ;IACJ;IAED;;;;;;;;;;;iDAO2BA,I;;;;;;gBACjBuC,I,GAAO,IAAA,CAAK1H,IAAL,CAAU2H,KAAV,CAAgBxC,IAAI,CAACyC,MAArB,EAA6BzC,IAAI,CAACyC,MAALzC,GAAc,IAAA,CAAKxF,QAAhD,C;gBACPkI,M,GAAS,IAAIC,MAAM,CAACC,UAAX,CAAA,C;gBACTC,c,GAAiBC,IAAI,CAACC,GAALD,CAAAA,C;;;uBAST,IAAA,CAAKI,QAAL,CAAcR,MAAd,EAAsBH,IAAtB,C;;;gBALNS,M,SAAAA,M;gBACAC,qB,SAAAA,qB;;uBAK4BjL,MAAM,CAAC,SAAD,EAAYgL,MAAZ,C;;gBAAhCG,iB;gBACAC,M,GAASC,IAAI,CACf,EAAA,CAAGC,MAAH,CAAUC,IAAV,CAAe,IAAIC,UAAJ,CAAeL,iBAAf,CAAf,EAAkD,UAACpH,IAAD,EAAO0H,IAAP,EAAA;kBAAA,OAAgB1H,IAAI,GAAG2H,MAAM,CAACC,YAAPD,CAAoBD,IAApBC,CAAvB;gBAAA,CAAlD,EAAoG,EAApG,CADe,C;gBAGnB,IAAA,CAAKE,gBAAL,CAAsB5D,IAAtB,EAA4BgD,MAA5B,CAAA;gBAEAhD,IAAI,CAACoD,MAALpD,GAAcoD,MAAdpD;gBACAA,IAAI,CAACsB,KAALtB,GAAatH,uBAAbsH;gBACAA,IAAI,CAACuC,IAALvC,GAAYuC,IAAZvC;gBAEA,IAAA,CAAK7F,mBAAL,IAA4B,CAA5B;gBACM0J,uB,GAA0Bf,IAAI,CAACC,GAALD,CAAAA,C;gBAEhC9C,IAAI,CAAC8D,MAAL9D,GAAc;kBACV+D,cAAc,EAAEF,uBAAuB,GAAGhB,cADhC;kBAEVmB,QAAQ,EAAEf,qBAAqB,GAAGJ,cAFxB;kBAGVoB,gBAAgB,EAAEJ,uBAAuB,GAAGZ;gBAHlC,CAAdjD;gBAMA,IAAA,CAAKb,gBAAL,CAAA,CAAA;;;;;;gBAEA,IAAA,CAAK+E,iBAAL,CAAA,SAAA,CAAA,EAAA,EAA8BlE,IAA9B,CAAA;;;;;;;;;;;;;IAIR;;;;;;;;;IA6NA;;;;;;;;uCAQmB/C,Q,EAAwB;MAAA,IAC/BO,MAD+B,GACXP,QADW,CAC/BO,MAD+B;QACvBmC,OADuB,GACX1C,QADW,CACvB0C,OADuB;MAEvC,IAAID,YAAY,GAAGvH,sBAAnB;MAEA,IAAIwH,OAAJ,EAAa;QACT,IAAMC,aAAa,GAAGC,QAAQ,CAACF,OAAO,CAAC,aAAD,CAAR,EAAyB,EAAzB,CAA9B;QAEA,IAAI,CAAC+G,MAAM,CAAC9O,KAAP8O,CAAa9G,aAAb8G,CAAL,EAAkC;UAC9BhH,YAAY,GAAGE,aAAa,GAAG,IAA/BF;QACH;MACJ;MAED,IAAMiH,mBAAmB,GAAG7O,8BAA8B,CACtD,IAAA,CAAKyB,MAAL,CAAY+E,mBAD0C,EAEtD,IAAA,CAAK/E,MAAL,CAAYgF,eAF0C,EAGtD,IAAA,CAAK9D,gBAHiD,CAA1D,CAZuC,CAiBvC;MACA;MACA;;MACA,IAAI+C,MAAM,KAAK,GAAf,EAAoB;QAChB,IAAA,CAAK/C,gBAAL,IAAyB,CAAzB;MACH;MAED,IAAM4D,YAAY,GAAGqB,YAAY,IAAIiH,mBAArC;MACA,IAAA,CAAKvI,UAAL,CAAA,qBAAA,CAAA,MAAA,CAAsCC,YAAtC,EAAA,KAAA,CAAA,CAAA;MACA,IAAA,CAAK+B,oBAAL,GAA4B3B,UAAU,CAAC,IAAA,CAAKqD,aAAN,EAAqBzD,YAArB,CAAtC;IACH;IAED;;;;;;;;qCAMuB;MACnB,KAAK,IAAIgE,CAAC,GAAG,IAAA,CAAK/H,wBAAlB,EAA4C+H,CAAC,GAAG,IAAA,CAAKvI,KAAL,CAAW+H,MAA3D,EAAmEQ,CAAC,IAAI,CAAxE,EAA2E;QACvE,IAAMrC,IAAI,GAAG,IAAA,CAAKlG,KAAL,CAAWuI,CAAX,CAAb;QAEA,IAAIrC,IAAI,CAACsB,KAALtB,KAAetH,uBAAnB,EAA4C;UACxC;UACA;UACA,IAAA,CAAKyB,mBAAL,IAA4B,CAA5B;UACA,IAAA,CAAKC,iBAAL,IAA0B,CAA1B;UACA,IAAI4F,IAAI,CAAC4G,QAAT,EAAmB;YACf5G,IAAI,CAAC6G,OAAL7G,CAAAA,CAAAA;UACH,CAFD,MAEO;YACHA,IAAI,CAACO,MAALP,CAAAA,CAAAA;UACH;UACD;QACH;MACJ;IACJ;IAED;;;;;;;;8CAMmC;MAC/B,OAAO,CAAC,IAAA,CAAK1D,WAAL,CAAA,CAAD,IAAuB,IAAA,CAAKlC,iBAAL,GAAyB,IAAA,CAAKb,MAAL,CAAYoD,WAA5D,IAA2E,IAAA,CAAKxC,mBAAL,GAA2B,CAA7G;IACH;IAED;;;;;;;;;qDAOuC;MACnC,IAAI6F,IAAI,GAAG,IAAA,CAAKlG,KAAL,CAAW,IAAA,CAAKQ,wBAAhB,CAAX;MACA,OAAO0F,IAAI,IAAIA,IAAI,CAACsB,KAALtB,KAAexH,mBAA9B,EAAmD;QAC/C,IAAA,CAAK8B,wBAAL,IAAiC,CAAjC;QACA0F,IAAI,GAAG,IAAA,CAAKlG,KAAL,CAAW,IAAA,CAAKQ,wBAAhB,CAAP0F;MACH;IACJ;IAED;;;;;;;IAOA;;;;;;;oCAOsB;MAClB,IAAA,CAAK/F,kBAAL,GAA0B8L,IAAI,CAACe,IAALf,CAAU,IAAA,CAAKlL,IAAL,CAAUY,IAAV,GAAiB,IAAA,CAAKjB,QAAhCuL,CAA1B;MAEA,KAAK,IAAI1D,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,IAAA,CAAKpI,kBAAzB,EAA6CoI,CAAC,IAAI,CAAlD,EAAqD;QACjD,IAAMI,MAAM,GAAGJ,CAAC,GAAG,IAAA,CAAK7H,QAAxB;QACA,IAAMuM,eAAe,GAAGhB,IAAI,CAACiB,GAALjB,CAAStD,MAAM,GAAG,IAAA,CAAKjI,QAAvBuL,EAAiC,IAAA,CAAKlL,IAAL,CAAUY,IAA3CsK,CAAAA,GAAmDtD,MAA3E;QACA,IAAMzC,IAAI,GAAG,IAAIzH,YAAJ,CACT,IAAA,CAAKe,OADI,EAET+I,CAFS,EAGTI,MAHS,EAITsE,eAJS,EAKT,IAAA,CAAKlM,IAAL,CAAUY,IALD,EAMT,IAAA,CAAKoD,SANI,EAOT,IAAA,CAAKC,gBAPI,EAQT,IAAA,CAAKvF,MARI,EAST,IAAA,CAAK0N,oBATI,EAUT,IAAA,CAAKC,wBAVI,EAWT,IAAA,CAAKhG,cAXI,EAYT,IAAA,CAAKiG,sBAZI,CAAb;QAcA,IAAA,CAAKrN,KAAL,CAAWsN,IAAX,CAAgBpH,IAAhB,CAAA;MACH;IACJ;IAED;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;sDA4B2C;MACvC,IAAMqH,eAAe,GAAG,IAAA,CAAKxM,IAAL,CAAUY,IAAlC;MACA,IAAM6L,uBAAuB,GAAGzP,sCAAsC,CAAC,IAAA,CAAKgD,IAAN,CAAtE;MAEA,IAAIwM,eAAe,KAAK,IAAA,CAAK7L,eAAzB6L,IAA4CC,uBAAuB,KAAK,IAAA,CAAK5L,uBAAjF,EAA0G;QACtG,IAAA,CAAKqC,mBAAL,CACI,IADJ,EAEIhF,yCAFJ,EAGI,IAAI,CAACkF,SAAL,CAAe;UACXsJ,OAAO,EAAE,IAAA,CAAK/L,eADH;UAEXgM,OAAO,EAAEH,eAFE;UAGXI,eAAe,EAAE,IAAA,CAAK/L,uBAHX;UAIXgM,eAAe,EAAEJ;QAJN,CAAf,CAHJ,CAAA;QAUA,OAAO,IAAP;MACH;MAED,OAAO,KAAP;IACH;IAED;;;;;;;;;6BAOe;MACX,IAAI,IAAA,CAAKhL,WAAL,CAAA,CAAJ,EAAwB;QACpB;MACH,CAHU,CAKX;;MACA,IAAA,CAAKxC,KAAL,CAAWiG,OAAX,CAAmB,UAAA,IAAI,EAAI;QACvBC,IAAI,CAACC,MAALD,CAAAA,CAAAA;MACH,CAFD,CAAA;MAIA,IAAA,CAAKlG,KAAL,GAAa,EAAb;MACAqG,YAAY,CAAC,IAAA,CAAK3B,oBAAN,CAAZ2B;MACAA,YAAY,CAAC,IAAA,CAAKC,oBAAN,CAAZD;MACA,IAAA,CAAKE,YAAL,CAAA,CAAA;MACA,IAAA,CAAKK,OAAL,CAAA,CAAA;IACH;IAED;;;;;;;;;;iDAMsB3E,I;;;;;;sBACd,IAAA,CAAKb,SAAL,IAAkBa,IAAI,CAAC4B,Y;;;;gBACvB,IAAA,CAAKvC,MAAL,GAAcW,IAAI,CAAC4B,YAAL5B,CAAkB4L,SAAlB5L,CAA4B2C,EAA1C;;;qBAGA,IAAA,CAAKvD,gB;;;;gBACL,IAAA,CAAKE,QAAL,GAAgB,IAAA,CAAKF,gBAAL,CAAsB,IAAA,CAAKE,QAA3B,CAAhB;;;gBAIEuM,S,GAAY,IAAA,CAAKvM,QAAL,CAAcwM,MAAd,CAAqB,IAAA,CAAKxM,QAAL,CAAcyM,WAAd,CAA0B,GAA1B,CAArB,CAAA,IAAwD,E,EAC1E;;gBACA,IAAA,CAAKzM,QAAL,GAAA,EAAA,CAAA,MAAA,CAAmB,IAAA,CAAKA,QAAL,CAAcwM,MAAd,CAAqB,CAArB,EAAwB,IAAA,CAAKxM,QAAL,CAAcyM,WAAd,CAA0B,GAA1B,CAAxB,CAAnB,EAAA,GAAA,CAAA,CAAA,MAAA,CAA8EhF,IAAI,CAACC,GAALD,CAAAA,CAA9E,CAAA,CAAA,MAAA,CAA2F8E,SAA3F,CAAA;;;;;;;;;;;;;IAGJ;;;;;;;;qCAMiB1J,K,EAAwB;MACrC,IAAI,CAACA,KAAL,EAAY;QACR,OAAO,CAAA,CAAP;MACH;MAHoC,IAK7BjB,QAL6B,GAKhBiB,KALgB,CAK7BjB,QAL6B;MAMrC,IAAI,CAACA,QAAL,EAAe;QACX,OAAO,CAAA,CAAP;MACH;MAED,IAAIA,QAAQ,CAACO,MAATP,KAAoB,GAAxB,EAA6B;QACzB,OAAOA,QAAP;MACH;MAED,OAAOA,QAAQ,CAAClB,IAAhB;IACH;;;EA5sCwBnD,Y;AA+sC7B,eAAeS,cAAf","sourcesContent":["/**\n * @flow\n * @file Multiput upload\n * @author Box\n */\n\nimport noop from 'lodash/noop';\nimport isNaN from 'lodash/isNaN';\nimport { getFileLastModifiedAsISONoMSIfPossible, getBoundedExpBackoffRetryDelay } from '../../utils/uploads';\nimport { retryNumOfTimes } from '../../utils/function';\nimport { digest } from '../../utils/webcrypto';\nimport hexToBase64 from '../../utils/base64';\nimport createWorker from '../../utils/uploadsSHA1Worker';\nimport {\n    DEFAULT_RETRY_DELAY_MS,\n    ERROR_CODE_UPLOAD_STORAGE_LIMIT_EXCEEDED,\n    HTTP_STATUS_CODE_FORBIDDEN,\n    MS_IN_S,\n} from '../../constants';\nimport MultiputPart, {\n    PART_STATE_UPLOADED,\n    PART_STATE_UPLOADING,\n    PART_STATE_DIGEST_READY,\n    PART_STATE_NOT_STARTED,\n} from './MultiputPart';\nimport BaseMultiput from './BaseMultiput';\nimport type { MultiputConfig } from '../../common/types/upload';\nimport type { StringAnyMap } from '../../common/types/core';\nimport type { APIOptions } from '../../common/types/api';\n\n// Constants used for specifying log event types.\n\n// This type is a catch-all for create session errors that aren't 5xx's (for which we'll do\n// retries) and aren't specific 4xx's we know how to specifically handle (e.g. out of storage).\nconst LOG_EVENT_TYPE_CREATE_SESSION_MISC_ERROR = 'create_session_misc_error';\nconst LOG_EVENT_TYPE_CREATE_SESSION_RETRIES_EXCEEDED = 'create_session_retries_exceeded';\nconst LOG_EVENT_TYPE_FILE_CHANGED_DURING_UPLOAD = 'file_changed_during_upload';\nconst LOG_EVENT_TYPE_PART_UPLOAD_RETRIES_EXCEEDED = 'part_upload_retries_exceeded';\nconst LOG_EVENT_TYPE_COMMIT_RETRIES_EXCEEDED = 'commit_retries_exceeded';\nconst LOG_EVENT_TYPE_WEB_WORKER_ERROR = 'web_worker_error';\nconst LOG_EVENT_TYPE_FILE_READER_RECEIVED_NOT_FOUND_ERROR = 'file_reader_received_not_found_error';\nconst LOG_EVENT_TYPE_PART_DIGEST_RETRIES_EXCEEDED = 'part_digest_retries_exceeded';\n\nclass MultiputUpload extends BaseMultiput {\n    clientId: ?string;\n\n    commitRetryCount: number;\n\n    createSessionNumRetriesPerformed: number;\n\n    destinationFileId: ?string;\n\n    folderId: string;\n\n    fileSha1: ?string;\n\n    firstUnuploadedPartIndex: number;\n\n    initialFileLastModified: ?string;\n\n    initialFileSize: number;\n\n    isResumableUploadsEnabled: boolean;\n\n    successCallback: Function;\n\n    progressCallback: Function;\n\n    options: APIOptions;\n\n    partSize: number;\n\n    parts: Array<MultiputPart>;\n\n    numPartsDigestComputing: number;\n\n    numPartsDigestReady: number;\n\n    numPartsNotStarted: number;\n\n    numPartsUploaded: number;\n\n    numPartsUploading: number;\n\n    numResumeRetries: number;\n\n    sessionEndpoints: Object;\n\n    sessionId: string;\n\n    totalUploadedBytes: number;\n\n    sha1Worker: Worker;\n\n    createSessionTimeout: TimeoutID;\n\n    commitSessionTimeout: TimeoutID;\n\n    /**\n     * [constructor]\n     *\n     * @param {Options} options\n     * @param {MultiputConfig} [config]\n     */\n    constructor(options: APIOptions, config?: MultiputConfig) {\n        super(\n            options,\n            {\n                createSession: null,\n                uploadPart: null,\n                listParts: null,\n                commit: null,\n                abort: null,\n                logEvent: null,\n            },\n            config,\n        );\n        this.parts = [];\n        this.options = options;\n        this.fileSha1 = null;\n        this.totalUploadedBytes = 0;\n        this.numPartsNotStarted = 0; // # of parts yet to be processed\n        this.numPartsDigestComputing = 0; // # of parts sent to the digest worker\n        this.numPartsDigestReady = 0; // # of parts with digest finished that are waiting to be uploaded.\n        this.numPartsUploading = 0; // # of parts with upload requests currently inflight\n        this.numPartsUploaded = 0; // # of parts successfully uploaded\n        this.firstUnuploadedPartIndex = 0; // Index of first part that hasn't been uploaded yet.\n        this.createSessionNumRetriesPerformed = 0;\n        this.partSize = 0;\n        this.commitRetryCount = 0;\n        this.clientId = null;\n        this.isResumableUploadsEnabled = false;\n        this.numResumeRetries = 0;\n    }\n\n    /**\n     * Reset values for uploading process.\n     */\n    reset() {\n        this.parts = [];\n        this.fileSha1 = null;\n        this.totalUploadedBytes = 0;\n        this.numPartsNotStarted = 0; // # of parts yet to be processed\n        this.numPartsDigestComputing = 0; // # of parts sent to the digest worker\n        this.numPartsDigestReady = 0; // # of parts with digest finished that are waiting to be uploaded.\n        this.numPartsUploading = 0; // # of parts with upload requests currently inflight\n        this.numPartsUploaded = 0; // # of parts successfully uploaded\n        this.firstUnuploadedPartIndex = 0; // Index of first part that hasn't been uploaded yet.\n        this.createSessionNumRetriesPerformed = 0;\n        this.partSize = 0;\n        this.commitRetryCount = 0;\n        this.numResumeRetries = 0;\n    }\n\n    /**\n     * Set information about file being uploaded\n     *\n     *\n     * @param {Object} options\n     * @param {File} options.file\n     * @param {string} options.folderId - Untyped folder id (e.g. no \"folder_\" prefix)\n     * @param {string} [options.fileId] - Untyped file id (e.g. no \"file_\" prefix)\n     * @param {string} options.sessionId\n     * @param {Function} [options.errorCallback]\n     * @param {Function} [options.progressCallback]\n     * @param {Function} [options.successCallback]\n     * @return {void}\n     */\n    setFileInfo({\n        file,\n        folderId,\n        errorCallback,\n        progressCallback,\n        successCallback,\n        overwrite = true,\n        conflictCallback,\n        fileId,\n    }: {\n        conflictCallback?: Function,\n        errorCallback?: Function,\n        file: File,\n        fileId: ?string,\n        folderId: string,\n        overwrite?: boolean,\n        progressCallback?: Function,\n        successCallback?: Function,\n    }): void {\n        this.file = file;\n        this.fileName = this.file.name;\n        this.folderId = folderId;\n        this.errorCallback = errorCallback || noop;\n        this.progressCallback = progressCallback || noop;\n        this.successCallback = successCallback || noop;\n        this.overwrite = overwrite;\n        this.conflictCallback = conflictCallback;\n        this.fileId = fileId;\n    }\n\n    /**\n     * Upload a given file\n     *\n     *\n     * @param {Object} options\n     * @param {File} options.file\n     * @param {string} options.folderId - Untyped folder id (e.g. no \"folder_\" prefix)\n     * @param {string} [options.fileId] - Untyped file id (e.g. no \"file_\" prefix)\n     * @param {Function} [options.errorCallback]\n     * @param {Function} [options.progressCallback]\n     * @param {Function} [options.successCallback]\n     * @return {void}\n     */\n    upload({\n        file,\n        fileDescription,\n        folderId,\n        errorCallback,\n        progressCallback,\n        successCallback,\n        overwrite = true,\n        conflictCallback,\n        fileId,\n    }: {\n        conflictCallback?: Function,\n        errorCallback?: Function,\n        file: File,\n        fileDescription: ?string,\n        fileId: ?string,\n        folderId: string,\n        overwrite?: boolean,\n        progressCallback?: Function,\n        successCallback?: Function,\n    }): void {\n        this.file = file;\n        this.fileName = this.file.name;\n        // These values are used as part of our (best effort) attempt to abort uploads if we detect\n        // a file change during the upload.\n        this.initialFileSize = this.file.size;\n        this.initialFileLastModified = getFileLastModifiedAsISONoMSIfPossible(this.file);\n        this.folderId = folderId;\n        this.errorCallback = errorCallback || noop;\n        this.progressCallback = progressCallback || noop;\n        this.successCallback = successCallback || noop;\n\n        this.sha1Worker = createWorker();\n        this.sha1Worker.addEventListener('message', this.onWorkerMessage);\n\n        this.conflictCallback = conflictCallback;\n        this.overwrite = overwrite;\n        this.fileId = fileId;\n        this.fileDescription = fileDescription;\n\n        this.makePreflightRequest();\n    }\n\n    /**\n     * Update uploadHost with preflight response and return the base uploadUrl\n     *\n     * @private\n     * @param {Object} response\n     * @param {Object} [response.data]\n     * @return {string}\n     */\n    getBaseUploadUrlFromPreflightResponse = ({ data }: { data: { upload_url?: string } }) => {\n        if (!data || !data.upload_url) {\n            return this.getBaseUploadUrl();\n        }\n\n        const splitUrl = data.upload_url.split('/');\n        // splitUrl[0] is the protocol (e.g., https:), splitUrl[2] is hostname (e.g., www.box.com)\n        this.uploadHost = `${splitUrl[0]}//${splitUrl[2]}`;\n        return this.getBaseUploadUrl();\n    };\n\n    /**\n     * Creates upload session. If a file ID is supplied, use the Chunked Upload File Version\n     * API to replace the file.\n     *\n     * @private\n     * @return {void}\n     */\n    preflightSuccessHandler = async (preflightResponse: Object): Promise<any> => {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        const uploadUrl = this.getBaseUploadUrlFromPreflightResponse(preflightResponse);\n        let createSessionUrl = `${uploadUrl}/files/upload_sessions`;\n\n        // Parallelism is currently detrimental to multiput upload performance in Zones, so set it to 1.\n        if (createSessionUrl.includes('fupload-ec2')) {\n            this.config.parallelism = 1;\n        }\n\n        // Set up post body\n        const postData: StringAnyMap = {\n            file_size: this.file.size,\n            file_name: this.fileName,\n        };\n\n        if (this.fileId) {\n            createSessionUrl = createSessionUrl.replace('upload_sessions', `${this.fileId}/upload_sessions`);\n        } else {\n            postData.folder_id = this.folderId;\n        }\n\n        try {\n            const response = await this.xhr.post({\n                url: createSessionUrl,\n                data: postData,\n            });\n            this.createSessionSuccessHandler(response.data);\n        } catch (error) {\n            const errorData = this.getErrorResponse(error);\n\n            if (errorData && errorData.status >= 500 && errorData.status < 600) {\n                this.createSessionErrorHandler(error);\n                return;\n            }\n\n            // Recover from 409 session_conflict.  The server will return the session information\n            // in context_info, so treat it as a success.\n            if (errorData && errorData.status === 409 && errorData.code === 'session_conflict') {\n                this.createSessionSuccessHandler(errorData.context_info.session);\n                return;\n            }\n\n            if (\n                (errorData &&\n                    errorData.status === HTTP_STATUS_CODE_FORBIDDEN &&\n                    errorData.code === ERROR_CODE_UPLOAD_STORAGE_LIMIT_EXCEEDED) ||\n                (errorData.status === HTTP_STATUS_CODE_FORBIDDEN &&\n                    errorData.code === 'access_denied_insufficient_permissions')\n            ) {\n                this.errorCallback(errorData);\n                return;\n            }\n\n            if (errorData && errorData.status === 409) {\n                this.resolveConflict(errorData);\n                this.createSessionRetry();\n                return;\n            }\n\n            // All other cases get treated as an upload failure.\n            this.sessionErrorHandler(error, LOG_EVENT_TYPE_CREATE_SESSION_MISC_ERROR, JSON.stringify(error));\n        }\n    };\n\n    /**\n     * Create session error handler.\n     * Retries the create session request or fails the upload.\n     *\n     * @private\n     * @param {Error} error\n     * @return {void}\n     */\n    createSessionErrorHandler = (error: Error): void => {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        if (this.createSessionNumRetriesPerformed < this.config.retries) {\n            this.createSessionRetry();\n            return;\n        }\n\n        this.consoleLog('Too many create session failures, failing upload');\n        this.sessionErrorHandler(error, LOG_EVENT_TYPE_CREATE_SESSION_RETRIES_EXCEEDED, JSON.stringify(error));\n    };\n\n    /**\n     * Schedule a retry for create session request upon failure\n     *\n     * @private\n     * @return {void}\n     */\n    createSessionRetry(): void {\n        const retryDelayMs = getBoundedExpBackoffRetryDelay(\n            this.config.initialRetryDelayMs,\n            this.config.maxRetryDelayMs,\n            this.createSessionNumRetriesPerformed,\n        );\n        this.createSessionNumRetriesPerformed += 1;\n        this.consoleLog(`Retrying create session in ${retryDelayMs} ms`);\n        this.createSessionTimeout = setTimeout(this.makePreflightRequest, retryDelayMs);\n    }\n\n    /**\n     * Handles a upload session success response\n     *\n     * @private\n     * @param {Object} data - Upload session creation success data\n     * @return {void}\n     */\n    createSessionSuccessHandler(data: any): void {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        const { id, part_size, session_endpoints } = data;\n\n        this.sessionId = id;\n        this.partSize = part_size;\n        this.sessionEndpoints = {\n            ...this.sessionEndpoints,\n            uploadPart: session_endpoints.upload_part,\n            listParts: session_endpoints.list_parts,\n            commit: session_endpoints.commit,\n            abort: session_endpoints.abort,\n            logEvent: session_endpoints.log_event,\n        };\n\n        this.populateParts();\n        this.processNextParts();\n    }\n\n    /**\n     * Resume uploading the given file\n     *\n     *\n     * @param {Object} options\n     * @param {File} options.file\n     * @param {string} options.folderId - Untyped folder id (e.g. no \"folder_\" prefix)\n     * @param {string} [options.fileId] - Untyped file id (e.g. no \"file_\" prefix)\n     * @param {string} options.sessionId\n     * @param {Function} [options.errorCallback]\n     * @param {Function} [options.progressCallback]\n     * @param {Function} [options.successCallback]\n     * @param {Function} [options.conflictCallback]\n     * @return {void}\n     */\n    resume({\n        file,\n        folderId,\n        errorCallback,\n        progressCallback,\n        sessionId,\n        successCallback,\n        overwrite = true,\n        conflictCallback,\n        fileId,\n    }: {\n        conflictCallback?: Function,\n        errorCallback?: Function,\n        file: File,\n        fileId: ?string,\n        folderId: string,\n        overwrite?: boolean,\n        progressCallback?: Function,\n        sessionId: string,\n        successCallback?: Function,\n    }): void {\n        this.setFileInfo({\n            file,\n            folderId,\n            errorCallback,\n            progressCallback,\n            successCallback,\n            conflictCallback,\n            overwrite,\n            fileId,\n        });\n        this.sessionId = sessionId;\n\n        if (!this.sha1Worker) {\n            this.sha1Worker = createWorker();\n        }\n        this.sha1Worker.addEventListener('message', this.onWorkerMessage);\n\n        this.getSessionInfo();\n    }\n\n    /**\n     * Get session information from API.\n     * Uses session info to commit a complete session or continue an in-progress session.\n     *\n     * @private\n     * @return {void}\n     */\n    getSessionInfo = async (): Promise<any> => {\n        const uploadUrl = this.getBaseUploadUrl();\n        const sessionUrl = `${uploadUrl}/files/upload_sessions/${this.sessionId}`;\n        try {\n            const response = await this.xhr.get({ url: sessionUrl });\n            this.getSessionSuccessHandler(response.data);\n        } catch (error) {\n            this.getSessionErrorHandler(error);\n        }\n    };\n\n    /**\n     * Handles a getSessionInfo success and either commits the session or continues to process\n     * the parts that still need to be uploaded.\n     *\n     * @param response\n     * @return {void}\n     */\n    getSessionSuccessHandler(data: any): void {\n        const { part_size, session_endpoints } = data;\n\n        // Set session information gotten from API response\n        this.partSize = part_size;\n        this.sessionEndpoints = {\n            ...this.sessionEndpoints,\n            uploadPart: session_endpoints.upload_part,\n            listParts: session_endpoints.list_parts,\n            commit: session_endpoints.commit,\n            abort: session_endpoints.abort,\n            logEvent: session_endpoints.log_event,\n        };\n\n        this.processNextParts();\n    }\n\n    /**\n     * Handle error from getting upload session.\n     * Restart uploads without valid sessions from the beginning of the upload process.\n     *\n     * @param error\n     * @return {void}\n     */\n    getSessionErrorHandler(error: Error): void {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        const errorData = this.getErrorResponse(error);\n        if (this.numResumeRetries > this.config.retries) {\n            this.errorCallback(errorData);\n            return;\n        }\n\n        if (errorData && errorData.status === 429) {\n            let retryAfterMs = DEFAULT_RETRY_DELAY_MS;\n            if (errorData.headers) {\n                const retryAfterSec = parseInt(\n                    errorData.headers['retry-after'] || errorData.headers.get('Retry-After'),\n                    10,\n                );\n                if (!isNaN(retryAfterSec)) {\n                    retryAfterMs = retryAfterSec * MS_IN_S;\n                }\n            }\n            this.retryTimeout = setTimeout(this.getSessionInfo, retryAfterMs);\n            this.numResumeRetries += 1;\n        } else if (errorData && errorData.status >= 400 && errorData.status < 500) {\n            // Restart upload process for errors resulting from invalid/expired session or no permission\n            this.parts.forEach(part => {\n                part.cancel();\n            });\n            this.reset();\n\n            // Abort session\n            clearTimeout(this.createSessionTimeout);\n            clearTimeout(this.commitSessionTimeout);\n            this.abortSession();\n            // Restart the uploading process from the beginning\n            const uploadOptions: Object = {\n                file: this.file,\n                folderId: this.folderId,\n                errorCallback: this.errorCallback,\n                progressCallback: this.progressCallback,\n                successCallback: this.successCallback,\n                overwrite: this.overwrite,\n                fileId: this.fileId,\n            };\n            this.upload(uploadOptions);\n        } else {\n            // Handle internet disconnects (error.request && !error.response) and (!error.request)\n            // Also handle any 500 error messages\n            this.retryTimeout = setTimeout(this.getSessionInfo, 2 ** this.numResumeRetries * MS_IN_S);\n            this.numResumeRetries += 1;\n        }\n    }\n\n    /**\n     * Session error handler.\n     * Retries the create session request or fails the upload.\n     *\n     * @private\n     * @param {?Error} error\n     * @param {string} logEventType\n     * @param {string} [logMessage]\n     * @return {Promise}\n     */\n    async sessionErrorHandler(error: ?Error, logEventType: string, logMessage?: string): Promise<any> {\n        if (!this.isResumableUploadsEnabled) {\n            this.destroy();\n        }\n        const errorData = this.getErrorResponse(error);\n        this.errorCallback(errorData);\n\n        try {\n            if (!this.sessionEndpoints.logEvent) {\n                throw new Error('logEvent endpoint not found');\n            }\n\n            await retryNumOfTimes(\n                (resolve: Function, reject: Function): void => {\n                    this.logEvent(logEventType, logMessage)\n                        .then(resolve)\n                        .catch(reject);\n                },\n                this.config.retries,\n                this.config.initialRetryDelayMs,\n            );\n            if (!this.isResumableUploadsEnabled) {\n                this.abortSession();\n            }\n        } catch (err) {\n            if (!this.isResumableUploadsEnabled) {\n                this.abortSession();\n            }\n        }\n    }\n\n    /**\n     * Aborts the upload session\n     *\n     * @private\n     * @return {void}\n     */\n    abortSession(): void {\n        if (this.sha1Worker) {\n            this.sha1Worker.terminate();\n        }\n\n        if (this.sessionEndpoints.abort && this.sessionId) {\n            this.xhr\n                .delete({\n                    url: this.sessionEndpoints.abort,\n                })\n                .then(() => {\n                    this.sessionId = '';\n                });\n        }\n    }\n\n    /**\n     * Part upload success handler\n     *\n     * @private\n     * @param {MultiputPart} part\n     * @return {void}\n     */\n    partUploadSuccessHandler = (part: MultiputPart): void => {\n        this.numPartsUploading -= 1;\n        this.numPartsUploaded += 1;\n        this.updateProgress(part.uploadedBytes, this.partSize);\n        this.processNextParts();\n    };\n\n    /**\n     * Part upload error handler\n     *\n     * @private\n     * @param {Error} error\n     * @param {string} eventInfo\n     * @return {void}\n     */\n    partUploadErrorHandler = (error: Error, eventInfo: string): void => {\n        this.sessionErrorHandler(error, LOG_EVENT_TYPE_PART_UPLOAD_RETRIES_EXCEEDED, eventInfo);\n        // Pause the rest of the parts.\n        // can't cancel parts because cancel destroys the part and parts are only created in createSession call\n        if (this.isResumableUploadsEnabled) {\n            // Reset uploading process for parts that were in progress when the upload failed\n            let nextUploadIndex = this.firstUnuploadedPartIndex;\n            while (this.numPartsUploading > 0) {\n                const part = this.parts[nextUploadIndex];\n                if (part && part.state === PART_STATE_UPLOADING) {\n                    part.reset();\n                    part.pause();\n\n                    this.numPartsUploading -= 1;\n                    this.numPartsDigestReady += 1;\n                }\n                nextUploadIndex += 1;\n            }\n        }\n    };\n\n    /**\n     * Update upload progress\n     *\n     * @private\n     * @param {number} prevUploadedBytes\n     * @param {number} newUploadedBytes\n     * @return {void}\n     */\n    updateProgress = (prevUploadedBytes: number, newUploadedBytes: number): void => {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        this.totalUploadedBytes += newUploadedBytes - prevUploadedBytes;\n        this.progressCallback({\n            loaded: this.totalUploadedBytes,\n            total: this.file.size,\n        });\n    };\n\n    /**\n     * Attempts to process more parts, except in the case where everything is done or we detect\n     * a file change (in which case we want to abort and not process more parts).\n     *\n     * @private\n     * @return {void}\n     */\n    processNextParts = (): void => {\n        if (this.failSessionIfFileChangeDetected()) {\n            return;\n        }\n\n        if (this.numPartsUploaded === this.parts.length && this.fileSha1) {\n            this.commitSession();\n            return;\n        }\n\n        this.updateFirstUnuploadedPartIndex();\n\n        while (this.canStartMorePartUploads()) {\n            this.uploadNextPart();\n        }\n\n        if (this.shouldComputeDigestForNextPart()) {\n            this.computeDigestForNextPart();\n        }\n    };\n\n    /**\n     * We compute digest for parts one at a time.  This is done for simplicity and also to guarantee that\n     * we send parts in order to the web sha1Worker (which is computing the digest for the entire file).\n     *\n     * @private\n     * @return {boolean} true if there is work to do, false otherwise.\n     */\n    shouldComputeDigestForNextPart(): boolean {\n        return (\n            !this.isDestroyed() &&\n            this.numPartsDigestComputing === 0 &&\n            this.numPartsNotStarted > 0 &&\n            this.numPartsDigestReady < this.config.digestReadahead\n        );\n    }\n\n    /**\n     * Find first part in parts array that doesn't have a digest, and compute its digest.\n\n     * @private\n     * @return {void}\n     */\n    computeDigestForNextPart(): void {\n        for (let i = this.firstUnuploadedPartIndex; i < this.parts.length; i += 1) {\n            const part = this.parts[i];\n            if (part.state === PART_STATE_NOT_STARTED) {\n                // Update the counters here instead of computeDigestForPart because computeDigestForPart\n                // can get called on retries\n                this.numPartsNotStarted -= 1;\n                this.numPartsDigestComputing += 1;\n                this.computeDigestForPart(part);\n                return;\n            }\n        }\n    }\n\n    /**\n     * Compute digest for this part\n     *\n     * @private\n     * @param {MultiputPart} part\n     * @return {Promise}\n     */\n    async computeDigestForPart(part: MultiputPart): Promise<any> {\n        const blob = this.file.slice(part.offset, part.offset + this.partSize);\n        const reader = new window.FileReader();\n        const startTimestamp = Date.now();\n\n        try {\n            const {\n                buffer,\n                readCompleteTimestamp,\n            }: {\n                buffer: ArrayBuffer,\n                readCompleteTimestamp: number,\n            } = await this.readFile(reader, blob);\n            const sha256ArrayBuffer = await digest('SHA-256', buffer);\n            const sha256 = btoa(\n                [].reduce.call(new Uint8Array(sha256ArrayBuffer), (data, byte) => data + String.fromCharCode(byte), ''),\n            );\n            this.sendPartToWorker(part, buffer);\n\n            part.sha256 = sha256;\n            part.state = PART_STATE_DIGEST_READY;\n            part.blob = blob;\n\n            this.numPartsDigestReady += 1;\n            const digestCompleteTimestamp = Date.now();\n\n            part.timing = {\n                partDigestTime: digestCompleteTimestamp - startTimestamp,\n                readTime: readCompleteTimestamp - startTimestamp,\n                subtleCryptoTime: digestCompleteTimestamp - readCompleteTimestamp,\n            };\n\n            this.processNextParts();\n        } catch (error) {\n            this.onPartDigestError(error, part);\n        }\n    }\n\n    /**\n     * Deal with a message from the worker (either a part sha-1 ready, file sha-1 ready, or error).\n     *\n     * @private\n     * @param {object} event\n     * @return {void}\n     */\n    onWorkerMessage = (event: Object) => {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        const { data } = event;\n        if (data.type === 'partDone') {\n            this.numPartsDigestComputing -= 1;\n            const { part } = data;\n            this.parts[part.index].timing.fileDigestTime = data.duration;\n            this.processNextParts();\n        } else if (data.type === 'done') {\n            this.fileSha1 = hexToBase64(data.sha1);\n            this.sha1Worker.terminate();\n            this.processNextParts();\n        } else if (data.type === 'error') {\n            this.sessionErrorHandler(null, LOG_EVENT_TYPE_WEB_WORKER_ERROR, JSON.stringify(data));\n        }\n    };\n\n    /**\n     * Sends a part to the sha1Worker\n     *\n     * @private\n     * @param {MultiputPart} part\n     * @param {ArrayBuffer} buffer\n     * @return {void}\n     */\n    sendPartToWorker = (part: MultiputPart, buffer: ArrayBuffer): void => {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        // Don't send entire part since XHR can't be cloned\n        const partInformation = {\n            index: part.index,\n            offset: part.offset,\n            size: part.partSize,\n        };\n        this.sha1Worker.postMessage(\n            {\n                part: partInformation,\n                fileSize: this.file.size,\n                partContents: buffer,\n            },\n            [buffer], // This transfers the ArrayBuffer to the worker context without copying contents.\n        );\n        this.consoleLog(`Part sent to worker: ${JSON.stringify(part)}.}`);\n    };\n\n    /**\n     * Error handler for part digest computation\n     *\n     * @private\n     * @param {Error} error\n     * @param {MultiputPart} part\n     * @return {void}\n     */\n    onPartDigestError = (error: Error, part: MultiputPart): void => {\n        this.consoleLog(`Error computing digest for part ${JSON.stringify(part)}: ${JSON.stringify(error)}`);\n\n        // When a FileReader is processing a file that changes on disk, Chrome reports a 'NotFoundError'\n        // and Safari reports a 'NOT_FOUND_ERR'. (Other browsers seem to allow the reader to keep\n        // going, either with the old version of the new file or the new one.) Since the error name\n        // implies that retrying will not help, we fail the session.\n        if (error.name === 'NotFoundError' || error.name === 'NOT_FOUND_ERR') {\n            this.sessionErrorHandler(null, LOG_EVENT_TYPE_FILE_READER_RECEIVED_NOT_FOUND_ERROR, JSON.stringify(error));\n            return;\n        }\n\n        if (this.failSessionIfFileChangeDetected()) {\n            return;\n        }\n\n        if (part.numDigestRetriesPerformed >= this.config.retries) {\n            this.sessionErrorHandler(null, LOG_EVENT_TYPE_PART_DIGEST_RETRIES_EXCEEDED, JSON.stringify(error));\n            return;\n        }\n\n        const retryDelayMs = getBoundedExpBackoffRetryDelay(\n            this.config.initialRetryDelayMs,\n            this.config.maxRetryDelayMs,\n            part.numDigestRetriesPerformed,\n        );\n        part.numDigestRetriesPerformed += 1;\n        this.consoleLog(`Retrying digest work for part ${JSON.stringify(part)} in ${retryDelayMs} ms`);\n\n        setTimeout(() => {\n            this.computeDigestForPart(part);\n        }, retryDelayMs);\n    };\n\n    /**\n     * Send a request to commit the upload.\n     *\n     * @private\n     * @return {void}\n     */\n    commitSession = (): void => {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        const stats = {\n            totalPartReadTime: 0,\n            totalPartDigestTime: 0,\n            totalFileDigestTime: 0,\n            totalPartUploadTime: 0,\n        };\n\n        const data = {\n            parts: this.parts\n                .map(part => {\n                    stats.totalPartReadTime += part.timing.readTime;\n                    stats.totalPartDigestTime += part.timing.subtleCryptoTime;\n                    stats.totalFileDigestTime += part.timing.fileDigestTime;\n                    stats.totalPartUploadTime += part.timing.uploadTime;\n                    return part.getPart();\n                })\n                .sort((part1, part2) => part1.offset - part2.offset),\n            attributes: {},\n        };\n\n        const fileLastModified = getFileLastModifiedAsISONoMSIfPossible(this.file);\n        if (fileLastModified) {\n            data.attributes.content_modified_at = fileLastModified;\n        }\n        if (this.fileDescription) {\n            data.attributes.description = this.fileDescription;\n        }\n\n        const clientEventInfo = {\n            avg_part_read_time: Math.round(stats.totalPartReadTime / this.parts.length),\n            avg_part_digest_time: Math.round(stats.totalPartDigestTime / this.parts.length),\n            avg_file_digest_time: Math.round(stats.totalFileDigestTime / this.parts.length),\n            avg_part_upload_time: Math.round(stats.totalPartUploadTime / this.parts.length),\n        };\n\n        // To make flow stop complaining about this.fileSha1 could potentially be undefined/null\n        const fileSha1: string = (this.fileSha1: any);\n        const headers = {\n            Digest: `sha=${fileSha1}`,\n            'X-Box-Client-Event-Info': JSON.stringify(clientEventInfo),\n        };\n\n        this.xhr\n            .post({ url: this.sessionEndpoints.commit, data, headers })\n            .then(this.commitSessionSuccessHandler)\n            .catch(this.commitSessionErrorHandler);\n    };\n\n    /**\n     * Commit response handler.  Succeeds the upload, retries the commit on 202\n     *\n     * @private\n     * @param {Object} response\n     * @return {void}\n     */\n    commitSessionSuccessHandler = (response: Object): void => {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        const { status, data } = response;\n\n        if (status === 202) {\n            this.commitSessionRetry(response);\n            return;\n        }\n\n        let { entries } = data;\n        // v2.1 API response format is different from v2.0. v2.1 returns individual upload entry directly inside data,\n        // while v2.0 returns a collection of entries under data.entries\n        if (!entries && data.id) {\n            entries = [data];\n        }\n\n        this.destroy();\n\n        if (this.successCallback && entries) {\n            this.successCallback(entries);\n        }\n    };\n\n    /**\n     * Commit error handler.\n     * Retries the commit or fails the multiput session.\n     *\n     * @private\n     * @param {Object} error\n     * @return {void}\n     */\n    commitSessionErrorHandler = (error: Object): void => {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        const { response } = error;\n\n        if (!response) {\n            // Some random error happened\n            this.consoleError(error);\n            return;\n        }\n\n        if (this.commitRetryCount >= this.config.retries) {\n            this.consoleLog('Too many commit failures, failing upload');\n            this.sessionErrorHandler(error, LOG_EVENT_TYPE_COMMIT_RETRIES_EXCEEDED, JSON.stringify(error));\n            return;\n        }\n\n        this.commitSessionRetry(response);\n    };\n\n    /**\n     * Retry commit.\n     * Retries the commit or fails the multiput session.\n     *\n     * @private\n     * @param {Object} response\n     * @return {void}\n     */\n    commitSessionRetry(response: Object): void {\n        const { status, headers } = response;\n        let retryAfterMs = DEFAULT_RETRY_DELAY_MS;\n\n        if (headers) {\n            const retryAfterSec = parseInt(headers['retry-after'], 10);\n\n            if (!Number.isNaN(retryAfterSec)) {\n                retryAfterMs = retryAfterSec * 1000;\n            }\n        }\n\n        const defaultRetryDelayMs = getBoundedExpBackoffRetryDelay(\n            this.config.initialRetryDelayMs,\n            this.config.maxRetryDelayMs,\n            this.commitRetryCount,\n        );\n        // If status is 202 then don't increment the retry count.\n        // In this case, frontend will keep retrying until it gets another status code.\n        // Retry interval = value specified for the Retry-After header in 202 response.\n        if (status !== 202) {\n            this.commitRetryCount += 1;\n        }\n\n        const retryDelayMs = retryAfterMs || defaultRetryDelayMs;\n        this.consoleLog(`Retrying commit in ${retryDelayMs} ms`);\n        this.commitSessionTimeout = setTimeout(this.commitSession, retryDelayMs);\n    }\n\n    /**\n     * Find first part in parts array that we can upload, and upload it.\n     *\n     * @private\n     * @return {void}\n     */\n    uploadNextPart(): void {\n        for (let i = this.firstUnuploadedPartIndex; i < this.parts.length; i += 1) {\n            const part = this.parts[i];\n\n            if (part.state === PART_STATE_DIGEST_READY) {\n                // Update the counters here instead of uploadPart because uploadPart\n                // can get called on retries\n                this.numPartsDigestReady -= 1;\n                this.numPartsUploading += 1;\n                if (part.isPaused) {\n                    part.unpause();\n                } else {\n                    part.upload();\n                }\n                break;\n            }\n        }\n    }\n\n    /**\n     * Checks if upload pipeline is full\n     *\n     * @private\n     * @return {boolean}\n     */\n    canStartMorePartUploads(): boolean {\n        return !this.isDestroyed() && this.numPartsUploading < this.config.parallelism && this.numPartsDigestReady > 0;\n    }\n\n    /**\n     * Functions that walk the parts array get called a lot, so we cache which part we should\n     * start work at to avoid always iterating through entire parts list.\n     *\n     * @private\n     * @return {void}\n     */\n    updateFirstUnuploadedPartIndex(): void {\n        let part = this.parts[this.firstUnuploadedPartIndex];\n        while (part && part.state === PART_STATE_UPLOADED) {\n            this.firstUnuploadedPartIndex += 1;\n            part = this.parts[this.firstUnuploadedPartIndex];\n        }\n    }\n\n    /**\n     * Get number of parts being uploaded\n     *\n     * @return {number}\n     */\n    getNumPartsUploading = (): number => this.numPartsUploading;\n\n    /**\n     * After session is created and we know the part size, populate the parts\n     * array.\n     *\n     * @private\n     * @return {void}\n     */\n    populateParts(): void {\n        this.numPartsNotStarted = Math.ceil(this.file.size / this.partSize);\n\n        for (let i = 0; i < this.numPartsNotStarted; i += 1) {\n            const offset = i * this.partSize;\n            const currentPartSize = Math.min(offset + this.partSize, this.file.size) - offset;\n            const part = new MultiputPart(\n                this.options,\n                i,\n                offset,\n                currentPartSize,\n                this.file.size,\n                this.sessionId,\n                this.sessionEndpoints,\n                this.config,\n                this.getNumPartsUploading,\n                this.partUploadSuccessHandler,\n                this.updateProgress,\n                this.partUploadErrorHandler,\n            );\n            this.parts.push(part);\n        }\n    }\n\n    /**\n     * Fails the session if the file's size or last modified has changed since the upload process\n     * began.\n     *\n     * This ensures that we don't upload a file that has parts from one file version and parts from\n     * another file version.\n     *\n     * This logic + the \"not found\" error logic in onWorkerError() is best effort and will not\n     * detect all possible file changes. This is because of browser differences. For example,\n     * -- In Safari, size and last modified will update when a file changes, and workers will\n     * get \"not found\" errors.\n     * -- In Chrome, size and last modified will update, but not in legacy drag and drop (that\n     * code path constructs a different file object). Workers will still get \"not found\" errors,\n     * though, so we can still detect changes even in legacy drag and drop.\n     * -- In IE 11/Edge, size will update but last modified will not. Workers will not get\n     * \"not found\" errors, but they may get a generic error saying that some bytes failed to be\n     * read.\n     * -- In Firefox, neither last modified nor size will update. Workers don't seem to get errors.\n     * (Not a whole lot we can do here...)\n     *\n     * Unfortunately, alternative solutions to catch more cases don't have a clear ROI (for\n     * example, doing a SHA-1 of the file before and after the upload is very expensive), so\n     * this is the best solution we have. We can revisit this if data shows that we need a better\n     * solution.\n     *\n     * @private\n     * @return {boolean} True if the session was failed, false if no action was taken\n     */\n    failSessionIfFileChangeDetected(): boolean {\n        const currentFileSize = this.file.size;\n        const currentFileLastModified = getFileLastModifiedAsISONoMSIfPossible(this.file);\n\n        if (currentFileSize !== this.initialFileSize || currentFileLastModified !== this.initialFileLastModified) {\n            this.sessionErrorHandler(\n                null,\n                LOG_EVENT_TYPE_FILE_CHANGED_DURING_UPLOAD,\n                JSON.stringify({\n                    oldSize: this.initialFileSize,\n                    newSize: currentFileSize,\n                    oldLastModified: this.initialFileLastModified,\n                    newLastModified: currentFileLastModified,\n                }),\n            );\n            return true;\n        }\n\n        return false;\n    }\n\n    /**\n     * Cancels an upload in progress by cancelling all upload parts.\n     * This cannot be undone or resumed.\n     *\n     * @private\n     * @return {void}\n     */\n    cancel(): void {\n        if (this.isDestroyed()) {\n            return;\n        }\n\n        // Cancel individual upload parts\n        this.parts.forEach(part => {\n            part.cancel();\n        });\n\n        this.parts = [];\n        clearTimeout(this.createSessionTimeout);\n        clearTimeout(this.commitSessionTimeout);\n        this.abortSession();\n        this.destroy();\n    }\n\n    /**\n     * Resolves upload conflict by overwriting or renaming\n     *\n     * @param {Object} response data\n     * @return {Promise}\n     */\n    async resolveConflict(data: Object): Promise<any> {\n        if (this.overwrite && data.context_info) {\n            this.fileId = data.context_info.conflicts.id;\n            return;\n        }\n        if (this.conflictCallback) {\n            this.fileName = this.conflictCallback(this.fileName);\n            return;\n        }\n\n        const extension = this.fileName.substr(this.fileName.lastIndexOf('.')) || '';\n        // foo.txt => foo-1513385827917.txt\n        this.fileName = `${this.fileName.substr(0, this.fileName.lastIndexOf('.'))}-${Date.now()}${extension}`;\n    }\n\n    /**\n     * Returns detailed error response\n     *\n     * @param {Object} error\n     * @return {Object}\n     */\n    getErrorResponse(error: ?Object): Object {\n        if (!error) {\n            return {};\n        }\n\n        const { response } = error;\n        if (!response) {\n            return {};\n        }\n\n        if (response.status === 401) {\n            return response;\n        }\n\n        return response.data;\n    }\n}\n\nexport default MultiputUpload;\n"]},"metadata":{},"sourceType":"module"}